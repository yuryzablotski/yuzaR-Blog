---
title: "{emmeans} Game-Changing R-package Squeezes Hidden Knowledge out of Models!"
description: |
  {emmeans} is one of the most capable, but at the same time one of the most mysterious and therefore underrated R packages. Let's demistify {emmeans} and uncover it's power!
author:
  - name: Yury Zablotski
    url: https://yuzar-blog.netlify.app/
date: "`r format(Sys.time(), '%B %d, %Y')`"
categories:
  - videos
  - statistics
  - models
preview: thumbnail_emmeans_1.png
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
    toc_depth: 6
    code_download: true
bibliography: /Users/zablotski/Documents/library.bib
#csl: american-political-science-association.csl
biblio-style: apalike
link-citations: yes
linkcolor: blue
#draft: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```



# This post as a video

I recommend to watch a video first, because I highlight things I talk about. It's ca. 14 minutes long.

```{r, eval=T, echo=F}
vembedr::embed_youtube("_okuMw4JFfU") 
```







```{r echo=FALSE}
library(tidyverse)       # for everything good in R
theme_set(theme_test())  # beautifies plots 
library(emmeans)         # multiply power of your results!

d <- mtcars %>% 
  mutate(cyl = factor(cyl),
         am  = factor(am),
         gear= factor(gear))

m <- lm(mpg ~ cyl, d)
library(sjPlot) # I made a video on this ðŸ“¦
plot_model(m, type = "pred", terms = "cyl")
```



# Why do we need {emmeans}?

- Have you ever wondered, why a "summary" function of an omnibus test like ANOVA, tells you that "the number of cylinders" significantly affects "car mileage" **without explaining how?** 

- Or have you ever been puzzled why a model compares all categories of a categorical predictor to **only the reference category, without comparing categories to each other?** 

- And what about those mysterious slopes with standard errors we get as model coefficients instead of the averages per category with 95% CIs that we actually want? 

- Moreover, "summary" function doesn't adjust p-values for multiple comparisons, which increases the probability of discovering nonsense by making too many type-I errors. 

![](type_1_errors.png)

- Summary function doesn't plot the results of a model and

- makes it almost impossible to interpret interactions! 

So, if you've ever been frustrated due to similar issues, you're definitely not alone! The **"summary" function doesn't actually provide a very useful summary**, and that's why we need {emmeans} package, which solves all those problems. 


```{r}
library(tidyverse)       # for everything good in R
theme_set(theme_test())  # beautifies plots 
library(emmeans)         # unleash power of your results!

d <- mtcars %>% 
  mutate(cyl  = factor(cyl),
         am   = factor(am),
         gear = factor(gear))

# omnibus test
aov(mpg ~ cyl, d) %>% summary()

# linear model
lm(mpg ~ cyl, d) %>% summary()
# lm(mpg ~ cyl, d) %>% summary() %>% plot()
```

Even the simplest "emmeans" application provides averages with CIs, compares all categories to each other pair-wisely, adjusts p-values for multiple comparisons and can be easily plotted. And that's just a beginning, because {emmeans} can do soo much more! But before we unleash the full power of {emmeans} package, we need to ...

```{r warnign = F}
# emmeans helps ;)
lm(mpg ~ cyl, d) %>% emmeans(pairwise ~ cyl) 
lm(mpg ~ cyl, d) %>% emmeans(pairwise ~ cyl) %>% plot()
```



# Understand what "emmeans" actually stands for

The "emmeans" is an abbreviation for **Estimated Marginal MEANS** (EMMs). 

- "estimated" is part of the name, since results are estimated (or predicted) only from models, not from data

- the "means" is part of of the name, because the averages themselves are often estimated. However, the term "means" is just a generalization, because for a median-based regression {emmeans} would estimate the marginal medians, while for a logistic regression {emmeans} calculates marginal probabilities. Cool, right?

```{r}
library(quantreg)
rq(mpg ~ cyl, d, tau = .5) %>% emmeans(~ cyl)
glm(am ~ cyl, d, family = binomial) %>% 
  emmeans(~ cyl, type = "response")
```

- so, the last part of the name is called "marginal", which describes a **group of values that we want to compute an average for**. For a categorical predictor, each category is a "margin". And for a numeric predictor, an average of that predictor is the "margin". For example, a marginal mean of "miles per gallon" for 4 cylinders is 26.7, and for 8 cylinders only 15.1, while the average "mpg" will be estimated for an average horsepower of 147.

```{r}
m <- lm(mpg ~ gear + am + hp, d)
ref_grid(m)
mean(d$hp)
```


**All margins of a model are combined in a REFERENCE GRID, which is the FOUNDATION for EMMs,** because we can estimate the mean at each point in the reference grid, or even define new points of the reference grid we want to estimate the means for. But let's take it one step at the time, starting with a ...

# Single categorical predictor

```{r}
m <- lm(mpg ~ cyl, d)
ref_grid(m)
emmeans(m, pairwise ~ cyl)
```

The reference grid of this model shows 3 points we can estimate mean "mpg" for, namely cylinders 4, 6 and 8. The "emmeans" function displays those means with their 95% CIs, compares the mileage of cylinders among each other pair-wisely and adjusts p-values for multiple comparison with a *Tukey* method by default. 

The default method of adjustment can easily be changed thought, which is very useful for several cases. First of all, people might want to use a famous *Bonferroni* method. However, *Bonferroni* correction is quite conservative and produces higher p-values as compared to *Tukey*, which is dangerous, because it increases chances to make a type II error - namely missing a discovery. 

![](type_2_errors.png)

Thus, *Bonferroni* correction is more useful when you have a lot of data. But if you only have a few observations or conduct an exploratory pilot study, you can even stop correcting for multiple comparisons by using, adjust = "none", argument. I personally prefer Benjamini & Hochberg (1995) method ("BH" or its alias "fdr") to control the false discovery rate. 

```{r}
emmeans(m, pairwise ~ cyl, adjust = "bonferroni")$contrasts
emmeans(m, pairwise ~ cyl, adjust = "none")$contrasts
emmeans(m, pairwise ~ cyl, adjust = "BH") # = â€œfdrâ€
```

# Summary of ... summaries ;)

Interestingly, the "emmeans" function shows us 95% CIs of the means, but not of the estimates of contrasts, which are differences between cylinders. On the other hand, the contrasts have p-values which test the null hypothesis that the difference is literally zero, while the "emmeans" section does not test any hypothesis and therefore has no p-values. 

We could greatly enhance the output of "emmeans" by using the "infer = TRUE" argument. This produces 95% CIs for the differences among cylinders, which is more useful than the standard error (SE). It also tests the null hypothesis that the means are actually zero. However, testing "emmeans" against zero is not particularly useful â€“ which is why p-values are not usually shown. But it makes a lot more sense to test them against some target mileage, let's say 14. For that, we can use the "null" argument to set the null hypothesis to 14. This makes cylinder 8, with a mean mileage of 15.1, no longer significantly different from our new null hypothesis. The "pairwise" argument is removed, because otherwise the contrasts would also have been tested against 14.

```{r}
emmeans(m, pairwise ~ cyl, infer = T)
emmeans(m, ~ cyl, infer = T, null = 14, adjust = "mvt")
```



As you can see, the "emmeans" function does a great job of summarizing all the important results, while the "summary" function misses most of them. We can even go in the opposite direction and summarize the "emmeans" results themselves to include **only the most essential information**. For that we'll use the Pairwise P-value matrix ("pwpm") function, which presents results from "emmeans" and pairwise comparisons thereof in a most compact way, where:

- the upper triangle displays the "Tukey" adjusted P values, 
- the diagonal shows the Estimates (EMMs), and 
- the lower triangle compares the estimates between levels. 

In this way, rarely used information such as "df" or "t.ratios" is left out.

```{r}
emmeans(m, ~ cyl) %>% pwpm()
```


Another advantage of "emmeans" over "summary" function is that we can easily plot our estimates with their 95% confidence intervals by using a "plot" command. (The 95% confidence intervals are the default, but you can change them with "level" argument, if you want to.) But the advantages of using "emmeans" over "summary" doesn't stop there. The benefits are even more pronounced if we analyze numeric predictors or covariates.

```{r}
emmeans(m, pairwise ~ cyl)$emmeans %>% plot()
emmeans(m, pairwise ~ cyl, level = 0.5)$emmeans %>% plot()
```



# Single numeric predictor + altering the reference grid


Namely, instead of just looking at the average 20 miles per gallon for a boring average car (as represented by the mean "horsepower" of 147), we can estimate "mileages per gallon" for weak (imagine a baby car) and muscle cars (imagine a muscle car and a engine noise)? To do this, we'll *reduce our covariate* to only the *range* of "horsepower", from 52 to 335, which gives us a **much more informative** and less boring look at fuel efficiency. Particularly, weak cars drive further and strong cars drive **much less** than the average 20 miles per gallon.


```{r}
m <- lm(mpg ~ hp, d)
emmeans(m, ~ hp)
emmeans(m, ~ hp, cov.reduce = range)
```


Moreover, we can specify any particular values of a numeric predictor, which might be useful when we have a non-linear relationship, but still need to figure out the efficiency of cars at different values of horsepower. 

```{r}
m1 <- lm(mpg ~ poly(hp, 2), d) 

library(sjPlot) # I made a video on this ðŸ“¦
plot_model(m1, type = "pred", show.data = T)
```

Let's use 100, 200, and 300 "horsepowers" and not only plot the estimates, but also compare them statistically by using the "comparisons = TRUE" argument. The blue bars represent the 95% confidence intervals for the EMMs, and the red arrows show statistical comparisons among them. If an arrow from one mean overlaps with an arrow from another mean, the difference is not significant. 

```{r}
emmeans(m1, ~ hp, at = list(hp = c(100, 200, 300))) %>% 
  plot(comparisons = TRUE)
```

Speaking of significance: if we want to see the exact p-values for pairwise comparisons among the different "horsepowers," we again can add the "pairwise" argument in front of the tilde (~) and see that after crossing the 200 horsepower threshold, the mileage doesn't significant change anymore, but stays at around 14.5 miles. 

```{r}
emmeans(m1, pairwise ~ hp, at = list(hp = c(100, 200, 300)))
```

Now, having learned what "emmeans" does with one categorical and one numeric predictors, let's figure out what happens if we have both in a multiple model.


# One categorical + One numeric predictors

In models that include covariates, EMMs are often referred to as *adjusted means*. For example, consider a scenario where we want to understand the effect of profession on *salary.* We might include *age* as a covariate in our model because *salary* certainly changes over the lifetime. By holding *age* constant at its average, we are controlling for the influence of *age* and are able to better understand the unique effect of profession on *salary* and make more accurate predictions.

If you wonder whether we really need any covariate at all, you can compare the Akaike's Information Criterion (AIC) of a model with, to the model without this covariate. The lower AIC of the model with age indicates that the covariate improves the model and thus makes predictions of salary by profession indeed more realistic.


```{r}
library(ISLR)

set.seed(10)  # for reproducibility
salary <- Wage %>% 
    group_by(jobclass) %>% 
    sample_n(50)

m_no_age <- lm(wage ~ jobclass, salary)
m <- lm(wage ~ jobclass + age, salary)
AIC(m, m_no_age)
```


The average age of 41.39 years shows that industrial workers earn slightly below 100K, while the IT crowd earns over 116K, which is already a first insight into our question. However, we can go one step further and ask "emmeans" to provide salary estimates for different ages in order to see how strongly salary increases over a lifetime for different professions.

```{r}
ref_grid(m)
emmeans(m, ~ jobclass)
```


For instance, if people start working at 25 and finish working at 65 years old, we will see that IT professionals receive a salary of over 100K already at the beginning of their career at the age of 25, while factory workers only reach that 100K mark by the age of 42.

```{r}
emmeans(m, pairwise ~ age | jobclass, at = list(age = c(25, 42, 65)))$emmeans
```




# Two categorical predictors


```{r}
m <- lm(mpg ~ am + cyl, d)
ref_grid(m)
emmeans(m, pairwise ~ cyl)
```


The model with two categorical predictors works a little differently. If we examine the estimated marginal means (EMMs) of *cylinders* while adjusting for *automatic transmission*, the "emmeans" command indicates that the results are somehow averaged over the levels of the variable *"am"*. I was initially unsure of what this meant, so I calculated the means of cylinders separately for transmission 0 and 1 using "by" argument and averaged them to get the same EMMs we obtained initially.

- (24.8 + 27.4)  / 2 = 26.1
- (18.6 + 21.2)  / 2 = 19.9
- (14.7 + 17.3)  / 2 = 16

Oh, by the way, if you want to display the sample size of every level, use `calc = c(n = ".wgt.")` argument ;)


```{r}
emmeans(m, ~ cyl, by = "am", calc = c(n = ".wgt."))
```


So, in the case of a numeric covariate, "emmeans" are estimated for the mean of the covariate. However, for a categorical covariate, "emmeans" calculates the averages for each category and then takes the average of the estimated marginal means over the categories.

But what happens if we have two numeric predictors?


# Two numeric predictors


To answer this question, let's consider the horsepower and weight of cars in the same model. The reference grid tells us that the mileage will be calculated only for the averages of predictors, which is somewhat boring. However, using the "cov.reduce" argument we learned about today, we can tell a more interesting story that is already part of the model but would have gone untold if we had only used the "summary" function. In particular, weak (52 horsepower) and light (1.52 weight) cars are the most efficient, as they can drive the most distance (nearly 30 miles per gallon of fuel). If a weak car is heavy (5.42 weight), it can only manage to drive 14.5 miles, which is less than a light but sporty muscle car (335 horsepower) with a mileage of 20 miles per gallon. The most inefficient cars, however, are strong and heavy, which can only manage 5.5 miles per gallon, so you'll never pass a gas station. 


```{r}
m <- lm(mpg ~ hp + wt, d)
ref_grid(m)
emmeans(m, ~ wt | hp, cov.reduce = range)
```

Plotting the results supports our conclusion that increasing the *strength* and *weight* of cars decreases their efficiency. The only thing we would need to be absolutely sure of our finding is the p-values. However, if we use the "pairwise" argument in front of the tilde (~) to get contrasts between values, we oddly get identical results for different horsepower levels. This happens because in a multiple model **without interactions** we can only adjust the effect of one predictor, such as *weight*, while the other predictors are held constant and do not change or vary.


```{r}
plot_model(m, type = "pred", terms = c("wt", "hp [52, 335]"))
lm(mpg ~ hp + wt, d) %>% 
  emmeans(pairwise ~ wt | hp, cov.reduce = range)
```


However, when we introduce interactions, things dramatically improve, because we can calculate EMMs for every level of one predictor within every level of the other predictor, and we can easily obtain contrasts between levels with unique p-values. This, however, is a completely different story, because analyzing interactions can be very challenging, but at the same time, it is extremely rewarding because it allows us to extract even more valuable knowledge from models. Thus, if you want to step up your data science game and unleash the real power of {emmeans}, you should definitely [watch this video!](https://youtu.be/cqmMNR6x73g)

```{r}
lm(mpg ~ hp * wt, d) %>% 
  emmeans(pairwise ~ wt | hp, cov.reduce = range)
```



# What's next? ... Interactions!

```{r echo=FALSE}
m <- lm(mpg ~ cyl * am, data = d)

m_emmeans <- emmeans(m, pairwise ~ cyl | am)

emmip(m, cyl ~ am, CIs = TRUE)

plot(m_emmeans, comparisons = TRUE)

pwpp(m_emmeans[[1]], type = "response")+ # by = "am"
  geom_vline(xintercept = 0.05, linetype = 2) 

```

# Some bonus content

## "Cohenâ€™s d" Effect sizes

- you must specify the "emmGrid" object with the means to be compared, the estimated population SD sigma of the model, and its degrees of freedom "edf":

```{r}
eff_size(emmeans(m, ~ cyl), sigma = sigma(m), edf = 29)
```




---

If you think, I missed something, please comment on it, and Iâ€™ll improve this tutorial.

**Thank you for learning!**





