<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>yuzaR-Blog</title>
    <link>https://yuzar-blog.netlify.app/</link>
    <atom:link href="https://yuzar-blog.netlify.app/index.xml" rel="self" type="application/rss+xml"/>
    <description>Data Science with R
</description>
    <generator>Distill</generator>
    <lastBuildDate>Sun, 10 Jul 2022 00:00:00 +0000</lastBuildDate>
    <item>
      <title>R package reviews {report} How To Report Statistical Results!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-06-18-report</link>
      <description>


&lt;h1 id="this-post-as-a-video"&gt;This post as a video&lt;/h1&gt;
&lt;p&gt;I recommend to watch a video first, because I highlight things I talk
about. It‚Äôs less then 8 minutes long.&lt;/p&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/iMh9tPsuiik" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="why-do-we-need-report"&gt;Why do we need {report}?&lt;/h1&gt;
&lt;p&gt;The result of a statistical test are often hardly digestible. So,
what we really want is the small but condense peace of text about what
our result are and what they mean. And that‚Äôs what the {report} package
gives you.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-06-18-report/report_workflow.png" /&gt;&lt;/p&gt;
&lt;p&gt;Here is a preliminary list of objects you can report now, in Julne,
2022. However, the package constantly improves and will only get better
over time:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Correlations, t-tests, Wilcoxon tests, paired &amp;amp; unpaired
(htest)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ANOVAs one-way, two-way etc. (aov, anova, aovlist, ‚Ä¶)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bayes factors (from bayestestR)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;‚Ä¶ (more tests to come)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Regression models (glm, lm, ‚Ä¶)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Mixed-effects models (glmer, lmer, glmmTMB, ‚Ä¶)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bayesian models (stanreg, brms‚Ä¶)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Structural Equation Models (SEM) (from lavaan)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;‚Ä¶ (more models to come)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Model comparison (from performance())&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;System and packages (sessionInfo)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Dataframes and vectors&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;‚Ä¶ (more features to come)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="reporting-statistical-tests"&gt;1. Reporting Statistical Tests&lt;/h1&gt;
&lt;p&gt;Load all needed packages at once, to avoid interruptions.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(ISLR)        # provides &amp;quot;Wage&amp;quot; dataset
library(report)      # to report results
library(sjPlot)      # visualizes model results
library(flextable)   # for beautiful tables
library(tidyverse)   # provides a lot of useful stuff !!! 
library(ggstatsplot) # to visualize test results&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="welch-t-test"&gt;Welch t-test&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;t.test(wage ~ jobclass, data = Wage)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    Welch Two Sample t-test

data:  wage by jobclass
t = -11.489, df = 2714.9, p-value &amp;lt; 2.2e-16
alternative hypothesis: true difference in means between group 1. Industrial and group 2. Information is not equal to 0
95 percent confidence interval:
 -20.21940 -14.32378
sample estimates:
 mean in group 1. Industrial mean in group 2. Information 
                    103.3211                     120.5927 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The usual output of a t-test is ‚Ä¶ &lt;strong&gt;not really
appealing&lt;/strong&gt; ‚Ä¶ to say the least. And if we‚Äôd try to write down the
results, we might end up reporting only a p-value. However, if we add
only one word to this code, we‚Äôll get &lt;strong&gt;SOO MUCH
MORE&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t.test(wage ~ jobclass, data = Wage) %&amp;gt;% 
  report()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Effect sizes were labelled following Cohen‚Äôs (1988)
recommendations.&lt;/p&gt;
&lt;p&gt;The Welch Two Sample t-test testing the difference of wage by
jobclass (mean in group 1. Industrial = 103.32, mean in group 2.
Information = 120.59) suggests that the effect is negative,
statistically significant, and small (difference = -17.27, 95% CI
[-20.22, -14.32], t(2714.87) = -11.49, p &amp;lt; .001; Cohen‚Äôs d = -0.44,
95% CI [-0.52, -0.36])&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;First of all, we‚Äôll get a &lt;strong&gt;digestible&lt;/strong&gt; peace of
&lt;strong&gt;text, suitable for&lt;/strong&gt; any &lt;strong&gt;publication
instantly&lt;/strong&gt;, with &lt;strong&gt;all important statistics, brackets and
special characters&lt;/strong&gt;. If you think it‚Äôs not a big deal, try to
rewrite it at least once without a single mistake üòâ&lt;/li&gt;
&lt;li&gt;Secondly, it gives us the &lt;strong&gt;difference&lt;/strong&gt; between groups
with 95% Confidence Intervals, while the test only provides the
confidence intervals of ‚Ä¶ probably difference, but not &lt;strong&gt;the
difference itself - the very thing we are interested in&lt;/strong&gt;!&lt;/li&gt;
&lt;li&gt;On top of that, &lt;code&gt;report()&lt;/code&gt; function provides a humanly
&lt;strong&gt;readable p-value&lt;/strong&gt; of under 0.001, instead of the strange
scientific notation, nobody really likes and only a few understand.&lt;/li&gt;
&lt;li&gt;And finally, it not only &lt;strong&gt;calculates the effect size with 95%
Confidence Intervals&lt;/strong&gt; for us, which a classic test doesn‚Äôt do,
but also &lt;strong&gt;interprets&lt;/strong&gt; it and even &lt;strong&gt;provides a
reference&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="students-two-sample-t-test"&gt;Student‚Äôs Two Sample t-test&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;t.test(iris$Sepal.Width, iris$Sepal.Length, var.equal = TRUE) %&amp;gt;%
  report()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Effect sizes were labelled following Cohen‚Äôs (1988)
recommendations.&lt;/p&gt;
&lt;p&gt;The Two Sample t-test testing the difference between iris&lt;span
class="math inline"&gt;\(Sepal.Width and iris\)&lt;/span&gt;Sepal.Length (mean of
x = 3.06, mean of y = 5.84) suggests that the effect is negative,
statistically significant, and large (difference = -2.79, 95% CI [-2.94,
-2.64], t(298) = -36.46, p &amp;lt; .001; Cohen‚Äôs d = -4.21, 95% CI [-4.61,
-3.80])&lt;/p&gt;
&lt;h2 id="paired-two-sample-t-test"&gt;Paired Two Sample t-test&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(t.test(iris$Sepal.Width, iris$Sepal.Length, paired = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Effect sizes were labelled following Cohen‚Äôs (1988)
recommendations.&lt;/p&gt;
&lt;p&gt;The Paired t-test testing the difference between iris&lt;span
class="math inline"&gt;\(Sepal.Width and iris\)&lt;/span&gt;Sepal.Length (mean of
the differences = -2.79) suggests that the effect is negative,
statistically significant, and large (difference = -2.79, 95% CI [-2.94,
-2.63], t(149) = -34.82, p &amp;lt; .001; Cohen‚Äôs d = -2.84, 95% CI [-3.66,
-2.49])&lt;/p&gt;
&lt;h2 id="wilcoxon-rank-sum-test-aka-mann-whitney-test"&gt;Wilcoxon rank sum
test (aka Mann-Whitney test)&lt;/h2&gt;
&lt;p&gt;Reporting results of nonparametric tests, for example Wilcoxon test,
is even more useful! Because the &lt;code&gt;report()&lt;/code&gt; function
correctly says: ‚ÄúThe Wilcoxon rank sum test is testing &lt;strong&gt;the
difference in ranks&lt;/strong&gt;‚Ä¶‚Äù, while even some scientific papers
mistakenly say that Wilcoxon test is testing &lt;strong&gt;the difference in
medians&lt;/strong&gt;, which is just wrong, medians are only used to better
describe not-normally distributed data, but medians are not used to
compare groups. If fact the difference in ranks can be significant even
when medians are identical. Here again, &lt;code&gt;report()&lt;/code&gt; function
applies a &lt;strong&gt;rank biserial correlation coefficient&lt;/strong&gt; as a
&lt;strong&gt;suitable effect size for Wilcoxon rank sum test&lt;/strong&gt; with a
reference. As you can see, {report} package not only produces more
results in a suitable for publication form, but also &lt;strong&gt;ensures a
correct interpretation of results&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-06-18-report/equal_dedians.png" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;wilc_test &amp;lt;- wilcox.test(Wage$wage ~ Wage$jobclass) 
report(wilc_test)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Effect sizes were labelled following Funder‚Äôs (2019)
recommendations.&lt;/p&gt;
&lt;p&gt;The Wilcoxon rank sum test with continuity correction testing the
difference in ranks between Wage&lt;span class="math inline"&gt;\(wage and
Wage\)&lt;/span&gt;jobclass suggests that the effect is negative,
statistically significant, and medium (W = 8.53e+05, p &amp;lt; .001; r
(rank biserial) = -0.24, 95% CI [-0.28, -0.20])&lt;/p&gt;
&lt;p&gt;By the way, we can easily integrate &lt;strong&gt;parts of the
results&lt;/strong&gt; into the text of our manuscript, if we prepare our
manuscript in RStudio. For instance if we use
&lt;code&gt;report_statistics()&lt;/code&gt; function in the middle of the text,
only numbers from our test will be incorporated into the text. The
&lt;code&gt;report_effectsize()&lt;/code&gt; function would only report the effect
size. Here is how it looks like inside of RStudio and in the
manuscript:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-06-18-report/code_inside_of_text.png" /&gt;&lt;/p&gt;
&lt;p&gt;Workers in the IT-Industry earn significantly more (W = 8.53e+05, p
&amp;lt; .001; r (rank biserial) = -0.24, 95% CI [-0.28, -0.20]) as compared
to workers in Industrial jobs. This difference is medium (r (rank
biserial) = -0.24, 95% CI [-0.28, -0.20]) large and can not be
ignored.&lt;/p&gt;
&lt;h2 id="paired-wilcoxon-signed-rank-test"&gt;Paired Wilcoxon signed rank
test&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(wilcox.test(iris$Sepal.Width, iris$Sepal.Length, paired = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Effect sizes were labelled following Funder‚Äôs (2019)
recommendations.&lt;/p&gt;
&lt;p&gt;The Wilcoxon signed rank test with continuity correction testing the
difference in ranks between iris&lt;span class="math inline"&gt;\(Sepal.Width
and iris\)&lt;/span&gt;Sepal.Length suggests that the effect is negative,
statistically significant, and very large (W = 0.00, p &amp;lt; .001; r
(rank biserial) = -1.00, 95% CI [-1.00, -1.00])&lt;/p&gt;
&lt;h2 id="pearsons-correlation"&gt;Pearson‚Äôs correlation&lt;/h2&gt;
&lt;p&gt;Similarly we can easily report the results of either parametric
Pearson or non-parametric Spearman or Kendall correlations. Besides,
&lt;code&gt;report_table()&lt;/code&gt; function allows you to display your result
as a table instead of text (see Kendall‚Äôs correlation below).&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;cor.test(mtcars$mpg, mtcars$wt) %&amp;gt;% 
  report()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Effect sizes were labelled following Funder‚Äôs (2019)
recommendations.&lt;/p&gt;
&lt;p&gt;The Pearson‚Äôs product-moment correlation between mtcars&lt;span
class="math inline"&gt;\(mpg and mtcars\)&lt;/span&gt;wt is negative,
statistically significant, and very large (r = -0.87, 95% CI [-0.93,
-0.74], t(30) = -9.56, p &amp;lt; .001)&lt;/p&gt;
&lt;h2 id="spearmans-rank-correlation"&gt;Spearman‚Äôs rank correlation&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;cor.test(mtcars$mpg, mtcars$wt, method = &amp;quot;spearman&amp;quot;) %&amp;gt;% 
  report()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Effect sizes were labelled following Funder‚Äôs (2019)
recommendations.&lt;/p&gt;
&lt;p&gt;The Spearman‚Äôs rank correlation rho between mtcars&lt;span
class="math inline"&gt;\(mpg and mtcars\)&lt;/span&gt;wt is negative,
statistically significant, and very large (rho = -0.89, S = 10292.32, p
&amp;lt; .001)&lt;/p&gt;
&lt;h2 id="kendalls-rank-correlation-as-a-table"&gt;Kendall‚Äôs rank correlation
(as a table)&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;cor.test(mtcars$mpg, mtcars$wt, method = &amp;quot;kendall&amp;quot;) %&amp;gt;% 
  report_table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Parameter1 | Parameter2 |   tau |     z |      p |                         Method | Alternative
-----------------------------------------------------------------------------------------------
mtcars$mpg |  mtcars$wt | -0.73 | -5.80 | &amp;lt; .001 | Kendall&amp;#39;s rank correlation tau |   two.sided&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="reporting-anovas"&gt;Reporting ANOVAs&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;aov(wt ~ am + mpg, data = mtcars) %&amp;gt;% 
  report()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ANOVA (formula: wt ~ am + mpg) suggests that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The main effect of am is statistically significant and large (F(1,
29) = 69.21, p &amp;lt; .001; Eta2 (partial) = 0.70, 95% CI [0.54,
1.00])&lt;/li&gt;
&lt;li&gt;The main effect of mpg is statistically significant and large (F(1,
29) = 46.12, p &amp;lt; .001; Eta2 (partial) = 0.61, 95% CI [0.42,
1.00])&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Effect sizes were labelled following Field‚Äôs (2013)
recommendations.&lt;/p&gt;
&lt;h1 id="reporting-regression-models"&gt;2. Reporting Regression Models&lt;/h1&gt;
&lt;h2 id="reporting-general-linear-models"&gt;Reporting (General) Linear
Models&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;model &amp;lt;- lm(mpg ~ am + hp, data = mtcars)

summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
Call:
lm(formula = mpg ~ am + hp, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.3843 -2.2642  0.1366  1.6968  5.8657 

Coefficients:
             Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept) 26.584914   1.425094  18.655  &amp;lt; 2e-16 ***
am           5.277085   1.079541   4.888 3.46e-05 ***
hp          -0.058888   0.007857  -7.495 2.92e-08 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.909 on 29 degrees of freedom
Multiple R-squared:  0.782, Adjusted R-squared:  0.767 
F-statistic: 52.02 on 2 and 29 DF,  p-value: 2.55e-10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But enough about tests, let‚Äôs see how {report} package handles
models. First of all, the usual summary of a model provides some useful
information but the output is again, not very friendly to the human eye,
and it is not clear how to describe it. I bet 10 researchers would
report these results in 10 slightly different ways. In contrast {report}
package provides a standardized way to report model-results, and again
delivers &lt;strong&gt;soo much more then the classic
&lt;code&gt;summary()&lt;/code&gt;&lt;/strong&gt; function. Particularly,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it describes what kind of model we used, while the
&lt;code&gt;summary()&lt;/code&gt; does not&lt;/li&gt;
&lt;li&gt;it interprets the &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(adj.R^2\)&lt;/span&gt;, while the &lt;code&gt;summary()&lt;/code&gt;
does not&lt;/li&gt;
&lt;li&gt;it uncovers what is behind the &lt;em&gt;mysterious&lt;/em&gt; (Intercept),
while the &lt;code&gt;summary()&lt;/code&gt; assumes that you already know it&lt;/li&gt;
&lt;li&gt;and finally, &lt;code&gt;report()&lt;/code&gt; functions describes parameters
‚Äúam‚Äù and ‚Äúhp‚Äù by providing the slope with &lt;strong&gt;useful! 95% Confidence
Intervals&lt;/strong&gt;, while the &lt;code&gt;summary()&lt;/code&gt; gives you
&lt;strong&gt;not really useful Standard Error of the Mean&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(model) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We fitted a linear model (estimated using OLS) to predict mpg with am
and hp (formula: mpg ~ am + hp). The model explains a statistically
significant and substantial proportion of variance (R2 = 0.78, F(2, 29)
= 52.02, p &amp;lt; .001, adj. R2 = 0.77). The model‚Äôs intercept,
corresponding to am = 0 and hp = 0, is at 26.58 (95% CI [23.67, 29.50],
t(29) = 18.65, p &amp;lt; .001). Within this model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The effect of am is statistically significant and positive (beta =
5.28, 95% CI [3.07, 7.48], t(29) = 4.89, p &amp;lt; .001; Std. beta = 0.44,
95% CI [0.25, 0.62])&lt;/li&gt;
&lt;li&gt;The effect of hp is statistically significant and negative (beta =
-0.06, 95% CI [-0.07, -0.04], t(29) = -7.50, p &amp;lt; .001; Std. beta =
-0.67, 95% CI [-0.85, -0.49])&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Standardized parameters were obtained by fitting the model on a
standardized version of the dataset. 95% Confidence Intervals (CIs) and
p-values were computed using the Wald approximation.&lt;/p&gt;
&lt;p&gt;In fact, if used for models, the &lt;code&gt;report()&lt;/code&gt; function gives
you more than you might want to use. That is why you can apply a
&lt;strong&gt;&lt;code&gt;summary()&lt;/code&gt; command ON TOP OF THE REPORT&lt;/strong&gt; ü§£
in order to report only essential information.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(model) %&amp;gt;% summary()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We fitted a linear model to predict mpg with am and hp. The model‚Äôs
explanatory power is substantial (R2 = 0.78, adj. R2 = 0.77). The
model‚Äôs intercept is at 26.58 (95% CI [23.67, 29.50]). Within this
model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The effect of am is statistically significant and positive (beta =
5.28, 95% CI [3.07, 7.48], t(29) = 4.89, p &amp;lt; .001, Std. beta =
0.44)&lt;/li&gt;
&lt;li&gt;The effect of hp is statistically significant and negative (beta =
-0.06, 95% CI [-0.07, -0.04], t(29) = -7.50, p &amp;lt; .001, Std. beta =
-0.67)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Similarly to test results, you can display model results as a table
with the &lt;code&gt;report_table()&lt;/code&gt; command, or use different parts of
the report inside of your text with:
&lt;code&gt;report_model(), report_performance(), report_parameters(), report_statistics()&lt;/code&gt;
or &lt;code&gt;report_effectsize()&lt;/code&gt; functions:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_table(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Parameter   | Coefficient |         95% CI | t(29) |      p | Std. Coef. | Std. Coef. 95% CI |    Fit
-----------------------------------------------------------------------------------------------------
(Intercept) |       26.58 | [23.67, 29.50] | 18.65 | &amp;lt; .001 |  -2.32e-17 |    [-0.17,  0.17] |       
am          |        5.28 | [ 3.07,  7.48] |  4.89 | &amp;lt; .001 |       0.44 |    [ 0.25,  0.62] |       
hp          |       -0.06 | [-0.07, -0.04] | -7.50 | &amp;lt; .001 |      -0.67 |    [-0.85, -0.49] |       
            |             |                |       |        |            |                   |       
AIC         |             |                |       |        |            |                   | 164.01
BIC         |             |                |       |        |            |                   | 169.87
R2          |             |                |       |        |            |                   |   0.78
R2 (adj.)   |             |                |       |        |            |                   |   0.77
Sigma       |             |                |       |        |            |                   |   2.91&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_model(model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;linear model (estimated using OLS) to predict mpg with am and hp
(formula: mpg ~ am + hp)&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_performance(model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The model explains a statistically significant and substantial
proportion of variance (R2 = 0.78, F(2, 29) = 52.02, p &amp;lt; .001, adj.
R2 = 0.77)&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_parameters(model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The intercept is statistically significant and positive (beta =
26.58, 95% CI [23.67, 29.50], t(29) = 18.65, p &amp;lt; .001; Std. beta =
-2.32e-17, 95% CI [-0.17, 0.17]), The effect of am is statistically
significant and positive (beta = 5.28, 95% CI [3.07, 7.48], t(29) =
4.89, p &amp;lt; .001; Std. beta = 0.44, 95% CI [0.25, 0.62]), The effect of
hp is statistically significant and negative (beta = -0.06, 95% CI
[-0.07, -0.04], t(29) = -7.50, p &amp;lt; .001; Std. beta = -0.67, 95% CI
[-0.85, -0.49])&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_statistics(model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;beta = 26.58, 95% CI [23.67, 29.50], t(29) = 18.65, p &amp;lt; .001; Std.
beta = -2.32e-17, 95% CI [-0.17, 0.17], beta = 5.28, 95% CI [3.07,
7.48], t(29) = 4.89, p &amp;lt; .001; Std. beta = 0.44, 95% CI [0.25, 0.62],
beta = -0.06, 95% CI [-0.07, -0.04], t(29) = -7.50, p &amp;lt; .001; Std.
beta = -0.67, 95% CI [-0.85, -0.49]&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_effectsize(model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;very small (Std. beta = -2.32e-17, 95% CI [-0.17, 0.17]), small (Std.
beta = 0.44, 95% CI [0.25, 0.62]), medium (Std. beta = -0.67, 95% CI
[-0.85, -0.49])&lt;/p&gt;
&lt;h2 id="logistic-regression"&gt;Logistic regression&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;m &amp;lt;- glm(am ~ mpg, mtcars, family = binomial) 
report(m)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We fitted a logistic model (estimated using ML) to predict am with
mpg (formula: am ~ mpg). The model‚Äôs explanatory power is substantial
(Tjur‚Äôs R2 = 0.37). The model‚Äôs intercept, corresponding to mpg = 0, is
at -6.60 (95% CI [-12.33, -2.77], p = 0.005). Within this model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The effect of mpg is statistically significant and positive (beta =
0.31, 95% CI [0.12, 0.59], p = 0.008; Std. beta = 1.85, 95% CI [0.74,
3.54])&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Standardized parameters were obtained by fitting the model on a
standardized version of the dataset. 95% Confidence Intervals (CIs) and
p-values were computed using&lt;/p&gt;
&lt;h2 id="mixed-effects-multilevel-models"&gt;Mixed-effects / multilevel
models&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(lme4)

mixed_model &amp;lt;- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;summary(mixed_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Linear mixed model fit by REML [&amp;#39;lmerMod&amp;#39;]
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy

REML criterion at convergence: 1743.6

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.9536 -0.4634  0.0231  0.4634  5.1793 

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 612.10   24.741       
          Days         35.07    5.922   0.07
 Residual             654.94   25.592       
Number of obs: 180, groups:  Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.825  36.838
Days          10.467      1.546   6.771

Correlation of Fixed Effects:
     (Intr)
Days -0.138&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The {report} package can report &lt;strong&gt;logistic
regressions&lt;/strong&gt;, but this is not really surprising. Surprising is
however, that it can also easily handle &lt;strong&gt;Linear Mixed-Effects
models&lt;/strong&gt;, whose popularity and usage is currently exploding. The
function explicitly describes random effects and interprets the
explanatory power of the model with two coefficients of determination,
conditional &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; for the whole model
(including random effects) and the marginal &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt; for only fixed effects, or only
predictors without random effects.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(mixed_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We fitted a linear mixed model (estimated using REML and nloptwrap
optimizer) to predict Reaction with Days (formula: Reaction ~ Days). The
model included Days and Subject as random effects (formula: ~Days |
Subject). The model‚Äôs total explanatory power is substantial
(conditional R2 = 0.80) and the part related to the fixed effects alone
(marginal R2) is of 0.28. The model‚Äôs intercept, corresponding to Days =
0, is at 251.41 (95% CI [237.94, 264.87], t(174) = 36.84, p &amp;lt; .001).
Within this model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The effect of Days is statistically significant and positive (beta =
10.47, 95% CI [7.42, 13.52], t(174) = 6.77, p &amp;lt; .001; Std. beta =
0.54, 95% CI [0.38, 0.69])&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Standardized parameters were obtained by fitting the model on a
standardized version of the dataset. 95% Confidence Intervals (CIs) and
p-values were computed using&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_random(mixed_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The model included Days and Subject as random effects (formula: ~Days
| Subject)&lt;/p&gt;
&lt;h2
id="reporting-bayesian-models-and-bayesian-mixed-effects-models"&gt;Reporting
Bayesian Models and Bayesian Mixed-Effects models&lt;/h2&gt;
&lt;p&gt;Bayesian models can also be reported using the new &lt;strong&gt;Sequential
Effect eXistence and sIgnificance Testing&lt;/strong&gt; framework, or
abbreviated - &lt;strong&gt;SEXIT&lt;/strong&gt; üòÅ (I swear I did not made it
up).&lt;/p&gt;
&lt;p&gt;This report describes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how Markov Chain Monte Carlo was computed,&lt;/li&gt;
&lt;li&gt;which primers were used&lt;/li&gt;
&lt;li&gt;it calculates the coefficient of determination &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt; and interprets the performance of the
model&lt;/li&gt;
&lt;li&gt;conducts Bayesian probabilistic hypothesis testing via
&lt;strong&gt;SEXIT&lt;/strong&gt; üòÅ&lt;/li&gt;
&lt;li&gt;and provides references for reported metrics, so that you can learn
more if something is not completely clear&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The full report for Bayesian models is huge though, but here you also
can use parts of the report effortlessly. Just choose what you want to
include into your text with one of the following functions:
&lt;code&gt;report_priors(), report_model(), report_performance(), report_parameters(), report_statistics()&lt;/code&gt;
or &lt;code&gt;report_effectsize()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(rstanarm)

bayes_model &amp;lt;- stan_glm(mpg ~ qsec + wt, data = mtcars, refresh = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(bayes_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We fitted a Bayesian linear model (estimated using MCMC sampling with
4 chains of 2000 iterations and a warmup of 1000) to predict mpg with
qsec and wt (formula: mpg ~ qsec + wt). Priors over parameters were set
as normal (mean = 0.00, SD = 8.43) and normal (mean = 0.00, SD = 15.40)
distributions. The model‚Äôs explanatory power is substantial (R2 = 0.81,
95% CI [0.70, 0.90], adj. R2 = 0.79). The model‚Äôs intercept,
corresponding to qsec = 0 and wt = 0, is at 19.59 (95% CI [8.67,
31.05]). Within this model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The effect of qsec (Median = 0.93, 95% CI [0.37, 1.48]) has a 99.90%
probability of being positive (&amp;gt; 0), 98.55% of being significant
(&amp;gt; 0.30), and 0.25% of being large (&amp;gt; 1.81). The estimation
successfully converged (Rhat = 1.000) and the indices are reliable (ESS
= 4179)&lt;/li&gt;
&lt;li&gt;The effect of wt (Median = -5.04, 95% CI [-6.04, -3.99]) has a
100.00% probability of being negative (&amp;lt; 0), 100.00% of being
significant (&amp;lt; -0.30), and 100.00% of being large (&amp;lt; -1.81). The
estimation successfully converged (Rhat = 1.001) and the indices are
reliable (ESS = 3643)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following the Sequential Effect eXistence and sIgnificance Testing
(SEXIT) framework, we report the median of the posterior distribution
and its 95% CI (Highest Density Interval), along the probability of
direction (pd), the probability of significance and the probability of
being large. The thresholds beyond which the effect is considered as
significant (i.e., non-negligible) and large are |0.30| and |1.81|
(corresponding respectively to 0.05 and 0.30 of the outcome‚Äôs SD).
Convergence and stability of the Bayesian sampling has been assessed
using R-hat, which should be below 1.01 (Vehtari et al., 2019), and
Effective Sample Size (ESS), which should be greater than 1000 (Burkner,
2017).&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_priors(bayes_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Priors over parameters were set as normal (mean = 0.00, SD = 8.43)
and normal (mean = 0.00, SD = 15.40) distributions&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_model(bayes_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bayesian linear model (estimated using MCMC sampling with 4 chains of
2000 iterations and a warmup of 1000) to predict mpg with qsec and wt
(formula: mpg ~ qsec + wt). Priors over parameters were set as normal
(mean = 0.00, SD = 8.43) and normal (mean = 0.00, SD = 15.40)
distributions&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_performance(bayes_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The model‚Äôs explanatory power is substantial (R2 = 0.81, 95% CI
[0.70, 0.90], adj. R2 = 0.79)&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_parameters(bayes_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The intercept (Median = 19.59, 95% CI [8.67, 31.05]) has a 99.92%
probability of being positive (&amp;gt; 0), 99.92% of being significant
(&amp;gt; 0.30), and 99.83% of being large (&amp;gt; 1.81). The estimation
successfully converged (Rhat = 1.000) and the indices are reliable (ESS
= 3964), The effect of qsec (Median = 0.93, 95% CI [0.37, 1.48]) has a
99.90% probability of being positive (&amp;gt; 0), 98.55% of being
significant (&amp;gt; 0.30), and 0.25% of being large (&amp;gt; 1.81). The
estimation successfully converged (Rhat = 1.000) and the indices are
reliable (ESS = 4179), The effect of wt (Median = -5.04, 95% CI [-6.04,
-3.99]) has a 100.00% probability of being negative (&amp;lt; 0), 100.00% of
being significant (&amp;lt; -0.30), and 100.00% of being large (&amp;lt; -1.81).
The estimation successfully converged (Rhat = 1.001) and the indices are
reliable (ESS = 3643)&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_statistics(bayes_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Median = 19.59, 95% CI [8.67, 31.05], pd = 99.92%, 0% in ROPE; Std.
beta = 1.22e-03, 95% CI [-0.16, 0.16]; Rhat = 1.00, ESS = 3964.00,
Median = 0.93, 95% CI [0.37, 1.48], pd = 99.90%, 10.26% in ROPE; Std.
beta = 0.28, 95% CI [0.11, 0.45]; Rhat = 1.00, ESS = 4178.73, Median =
-5.04, 95% CI [-6.04, -3.99], pd = 100%, 0% in ROPE; Std. beta = -0.82,
95% CI [-0.98, -0.66]; Rhat = 1.00, ESS = 3643.13&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_effectsize(bayes_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;very small (Std. beta = -7.75e-04, 95% CI [-0.16, 0.16]), small (Std.
beta = 0.27, 95% CI [0.11, 0.45]), large (Std. beta = -0.82, 95% CI
[-0.98, -0.66])&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_table(bayes_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Parameter   | Median |         95% CI |     pd | % in ROPE |  Rhat |     ESS |                   Prior | Std. Median | Std_Median 95% CI |    Fit
-------------------------------------------------------------------------------------------------------------------------------------------------
(Intercept) |  19.59 | [ 8.67, 31.05] | 99.92% |        0% | 1.000 | 3964.00 | Normal (20.09 +- 15.07) |   -1.23e-03 |    [-0.17,  0.16] |       
qsec        |   0.93 | [ 0.37,  1.48] | 99.90% |    10.26% | 1.000 | 4179.00 |   Normal (0.00 +- 8.43) |        0.27 |    [ 0.12,  0.43] |       
wt          |  -5.04 | [-6.04, -3.99] |   100% |        0% | 1.001 | 3643.00 |  Normal (0.00 +- 15.40) |       -0.82 |    [-0.98, -0.65] |       
            |        |                |        |           |       |         |                         |             |                   |       
ELPD        |        |                |        |           |       |         |                         |             |                   | -79.02
LOOIC       |        |                |        |           |       |         |                         |             |                   | 158.04
WAIC        |        |                |        |           |       |         |                         |             |                   | 157.78
R2          |        |                |        |           |       |         |                         |             |                   |   0.81
R2 (adj.)   |        |                |        |           |       |         |                         |             |                   |   0.79
Sigma       |        |                |        |           |       |         |                         |             |                   |   2.64&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="exotic-and-not-supported-models"&gt;Exotic and not-supported models
üò® ???&lt;/h2&gt;
&lt;p&gt;Despite the large number of models supported, at the time of making
this blog (June 2022), {report} package doesn‚Äôt support all the models
in the world. But it evolves very quick. For instance when you found
similar ‚ÄúError message‚Äù to the one you see on the screen, go to this
link and let the authors know, what kind of models you want {report}
package to be able to handle.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;d &amp;lt;- foreign::read.dta(&amp;quot;https://stats.idre.ucla.edu/stat/data/hsbdemo.dta&amp;quot;)

m &amp;lt;- nnet::multinom(prog ~ ses + write, d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# weights:  15 (8 variable)
initial  value 219.722458 
iter  10 value 179.985215
final  value 179.981726 
converged&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(m)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error in report.default(m): Oops, objects of class [multinom, nnet] are not supported (yet) by report() :(

Want to help? Check out https://easystats.github.io/report/articles/new_models.html&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="reporting-data"&gt;3. Reporting Data&lt;/h1&gt;
&lt;h2 id="as-text"&gt;As text&lt;/h2&gt;
&lt;p&gt;Now, you can also quickly describe your data by simply using {report}
function on your dataset. It provides the most common descriptive
statistics for every variable, doesn‚Äôt matter numeric or
categorical.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(iris)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data contains 150 observations of the following 5 variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sepal.Length: n = 150, Mean = 5.84, SD = 0.83, Median = 5.80, MAD =
1.04, range: [4.30, 7.90], Skewness = 0.31, Kurtosis = -0.55, 0%
missing&lt;/li&gt;
&lt;li&gt;Sepal.Width: n = 150, Mean = 3.06, SD = 0.44, Median = 3.00, MAD =
0.44, range: [2, 4.40], Skewness = 0.32, Kurtosis = 0.23, 0%
missing&lt;/li&gt;
&lt;li&gt;Petal.Length: n = 150, Mean = 3.76, SD = 1.77, Median = 4.35, MAD =
1.85, range: [1, 6.90], Skewness = -0.27, Kurtosis = -1.40, 0%
missing&lt;/li&gt;
&lt;li&gt;Petal.Width: n = 150, Mean = 1.20, SD = 0.76, Median = 1.30, MAD =
1.04, range: [0.10, 2.50], Skewness = -0.10, Kurtosis = -1.34, 0%
missing&lt;/li&gt;
&lt;li&gt;Species: 3 levels, namely setosa (n = 50, 33.33%), versicolor (n =
50, 33.33%) and virginica (n = 50, 33.33%)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Besides, {Report} package works perfectly with famous {tidyverse}
packages, like {dplyr}. Thus, the data can be easily grouped by any
categorical variable, e.g.¬†Species, and the descriptive stats for every
level of the grouping variable will be returned:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;iris %&amp;gt;%
  select(-starts_with(&amp;quot;Sepal&amp;quot;)) %&amp;gt;%
  group_by(Species) %&amp;gt;%
  report() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;The data contains 150 observations, grouped by Species, of the following 3 variables:

- setosa (n = 50):
  - Petal.Length: n = 50, Mean = 1.46, SD = 0.17, Median = 1.50, MAD = 0.15, range: [1, 1.90], Skewness = 0.11, Kurtosis = 1.02, 0 missing
  - Petal.Width: n = 50, Mean = 0.25, SD = 0.11, Median = 0.20, MAD = 0.00, range: [0.10, 0.60], Skewness = 1.25, Kurtosis = 1.72, 0 missing

- versicolor (n = 50):
  - Petal.Length: n = 50, Mean = 4.26, SD = 0.47, Median = 4.35, MAD = 0.52, range: [3, 5.10], Skewness = -0.61, Kurtosis = 0.05, 0 missing
  - Petal.Width: n = 50, Mean = 1.33, SD = 0.20, Median = 1.30, MAD = 0.22, range: [1, 1.80], Skewness = -0.03, Kurtosis = -0.41, 0 missing

- virginica (n = 50):
  - Petal.Length: n = 50, Mean = 5.55, SD = 0.55, Median = 5.55, MAD = 0.67, range: [4.50, 6.90], Skewness = 0.55, Kurtosis = -0.15, 0 missing
  - Petal.Width: n = 50, Mean = 2.03, SD = 0.27, Median = 2.00, MAD = 0.30, range: [1.40, 2.50], Skewness = -0.13, Kurtosis = -0.60, 0 missing&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="as-table"&gt;As table&lt;/h2&gt;
&lt;p&gt;Want the same as a huge or a minimalistic table? No, problems! Use
&lt;code&gt;report_table()&lt;/code&gt; or &lt;code&gt;report_sample()&lt;/code&gt;
functions.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;iris %&amp;gt;%
  group_by(Species) %&amp;gt;%
  report_table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Group      |     Variable | n_Obs | Mean |   SD | Median |  MAD |  Min |  Max | Skewness | Kurtosis | n_Missing
---------------------------------------------------------------------------------------------------------------
versicolor | Sepal.Length |    50 | 5.94 | 0.52 |   5.90 | 0.52 | 4.90 | 7.00 |     0.11 |    -0.53 |         0
versicolor |  Sepal.Width |    50 | 2.77 | 0.31 |   2.80 | 0.30 | 2.00 | 3.40 |    -0.36 |    -0.37 |         0
versicolor | Petal.Length |    50 | 4.26 | 0.47 |   4.35 | 0.52 | 3.00 | 5.10 |    -0.61 |     0.05 |         0
versicolor |  Petal.Width |    50 | 1.33 | 0.20 |   1.30 | 0.22 | 1.00 | 1.80 |    -0.03 |    -0.41 |         0
virginica  | Sepal.Length |    50 | 6.59 | 0.64 |   6.50 | 0.59 | 4.90 | 7.90 |     0.12 |     0.03 |         0
virginica  |  Sepal.Width |    50 | 2.97 | 0.32 |   3.00 | 0.30 | 2.20 | 3.80 |     0.37 |     0.71 |         0
virginica  | Petal.Length |    50 | 5.55 | 0.55 |   5.55 | 0.67 | 4.50 | 6.90 |     0.55 |    -0.15 |         0
virginica  |  Petal.Width |    50 | 2.03 | 0.27 |   2.00 | 0.30 | 1.40 | 2.50 |    -0.13 |    -0.60 |         0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_sample(iris, group_by = &amp;quot;Species&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# Descriptive Statistics

Variable               | setosa (n=50) | versicolor (n=50) | virginica (n=50) | Total (n=150)
---------------------------------------------------------------------------------------------
Mean Sepal.Length (SD) |   5.01 (0.35) |       5.94 (0.52) |      6.59 (0.64) |   5.84 (0.83)
Mean Sepal.Width (SD)  |   3.43 (0.38) |       2.77 (0.31) |      2.97 (0.32) |   3.06 (0.44)
Mean Petal.Length (SD) |   1.46 (0.17) |       4.26 (0.47) |      5.55 (0.55) |   3.76 (1.77)
Mean Petal.Width (SD)  |   0.25 (0.11) |       1.33 (0.20) |      2.03 (0.27) |   1.20 (0.76)&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="reporting-r-environment-packages-system"&gt;4. Reporting R
environment, packages, system&lt;/h1&gt;
&lt;p&gt;And finally, using only one command:
&lt;code&gt;report(sessionInfo())&lt;/code&gt; you first report the Statistical
software you used for data analysis, secondly, you list ALL packages you
used and lastly you cite all packages you used automatically without any
typing mistakes! How cool is that? And if you want to know how to find
THE BEST MODEL which you then can report, check out {glmulti}
package!&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(sessionInfo())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Analyses were conducted using the R Statistical language (version
4.1.3; R Core Team, 2022) on macOS Big Sur/Monterey 10.16, using the
packages flextable (version 0.7.0; David Gohel, 2022), Rcpp (version
1.0.8.3; Dirk Eddelbuettel and Romain Francois, 2011), Matrix (version
1.4.1; Douglas Bates, Martin Maechler and Mikael Jagan, 2022), lme4
(version 1.1.29; Douglas Bates et al., 2015), ISLR (version 1.4; Gareth
James et al., 2021), rstanarm (version 2.21.3; Goodrich B et al., 2022),
ggplot2 (version 3.3.6; Wickham. ggplot2: Elegant Graphics for Data
Analysis. Springer-Verlag New York, 2016.), stringr (version 1.4.0;
Hadley Wickham, 2019), forcats (version 0.5.1; Hadley Wickham, 2021),
tidyr (version 1.2.0; Hadley Wickham and Maximilian Girlich, 2022),
readr (version 2.1.2; Hadley Wickham, Jim Hester and Jennifer Bryan,
2022), dplyr (version 1.0.9; Hadley Wickham et al., 2022), tibble
(version 3.1.7; Kirill M√ºller and Hadley Wickham, 2022), purrr (version
0.3.4; Lionel Henry and Hadley Wickham, 2020), sjPlot (version 2.8.10;
L√ºdecke D, 2021), report (version 0.5.1; Makowski et al., 2020),
ggstatsplot (version 0.9.3; Patil, 2021) and tidyverse (version
1.3.1.9000; Wickham et al., 2019).&lt;/p&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;David Gohel (2022). flextable: Functions for Tabular Reporting. R
package version 0.7.0. &lt;a
href="https://CRAN.R-project.org/package=flextable"
class="uri"&gt;https://CRAN.R-project.org/package=flextable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dirk Eddelbuettel and Romain Francois (2011). Rcpp: Seamless R and
C++ Integration. Journal of Statistical Software, 40(8), 1-18, &lt;a
href="doi:10.18637/jss.v040.i08"
class="uri"&gt;doi:10.18637/jss.v040.i08&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Douglas Bates, Martin Maechler and Mikael Jagan (2022). Matrix:
Sparse and Dense Matrix Classes and Methods. R package version 1.4-1. &lt;a
href="https://CRAN.R-project.org/package=Matrix"
class="uri"&gt;https://CRAN.R-project.org/package=Matrix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015).
Fitting Linear Mixed-Effects Models Using lme4. Journal of Statistical
Software, 67(1), 1-48. &lt;a href="doi:10.18637/jss.v067.i01"
class="uri"&gt;doi:10.18637/jss.v067.i01&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Gareth James, Daniela Witten, Trevor Hastie and Rob Tibshirani
(2021). ISLR: Data for an Introduction to Statistical Learning with
Applications in R. R package version 1.4. &lt;a
href="https://CRAN.R-project.org/package=ISLR"
class="uri"&gt;https://CRAN.R-project.org/package=ISLR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Goodrich B, Gabry J, Ali I &amp;amp; Brilleman S. (2022). rstanarm:
Bayesian applied regression modeling via Stan. R package version 2.21.3
&lt;a href="https://mc-stan.org/rstanarm"
class="uri"&gt;https://mc-stan.org/rstanarm&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;H. Wickham. ggplot2: Elegant Graphics for Data Analysis.
Springer-Verlag New York, 2016.&lt;/li&gt;
&lt;li&gt;Hadley Wickham (2019). stringr: Simple, Consistent Wrappers for
Common String Operations. R package version 1.4.0. &lt;a
href="https://CRAN.R-project.org/package=stringr"
class="uri"&gt;https://CRAN.R-project.org/package=stringr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hadley Wickham (2021). forcats: Tools for Working with Categorical
Variables (Factors). R package version 0.5.1. &lt;a
href="https://CRAN.R-project.org/package=forcats"
class="uri"&gt;https://CRAN.R-project.org/package=forcats&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hadley Wickham and Maximilian Girlich (2022). tidyr: Tidy Messy
Data. R package version 1.2.0. &lt;a
href="https://CRAN.R-project.org/package=tidyr"
class="uri"&gt;https://CRAN.R-project.org/package=tidyr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hadley Wickham, Jim Hester and Jennifer Bryan (2022). readr: Read
Rectangular Text Data. R package version 2.1.2. &lt;a
href="https://CRAN.R-project.org/package=readr"
class="uri"&gt;https://CRAN.R-project.org/package=readr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hadley Wickham, Romain Fran√ßois, Lionel Henry and Kirill M√ºller
(2022). dplyr: A Grammar of Data Manipulation. R package version 1.0.9.
&lt;a href="https://CRAN.R-project.org/package=dplyr"
class="uri"&gt;https://CRAN.R-project.org/package=dplyr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kirill M√ºller and Hadley Wickham (2022). tibble: Simple Data Frames.
R package version 3.1.7. &lt;a
href="https://CRAN.R-project.org/package=tibble"
class="uri"&gt;https://CRAN.R-project.org/package=tibble&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lionel Henry and Hadley Wickham (2020). purrr: Functional
Programming Tools. R package version 0.3.4. &lt;a
href="https://CRAN.R-project.org/package=purrr"
class="uri"&gt;https://CRAN.R-project.org/package=purrr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;L√ºdecke D (2021). &lt;em&gt;sjPlot: Data Visualization for Statistics in
SocialScience&lt;/em&gt;. R package version 2.8.10, &amp;lt;URL:&lt;a
href="https://CRAN.R-project.org/package=sjPlot"
class="uri"&gt;https://CRAN.R-project.org/package=sjPlot&lt;/a&gt;&amp;gt;.&lt;/li&gt;
&lt;li&gt;Makowski, D., Ben-Shachar, M.S., Patil, I. &amp;amp; L√ºdecke, D. (2020).
Automated Results Reporting as a Practical Tool to Improve
Reproducibility and Methodological Best Practices Adoption. CRAN.
Available from &lt;a href="https://github.com/easystats/report"
class="uri"&gt;https://github.com/easystats/report&lt;/a&gt;. doi: .&lt;/li&gt;
&lt;li&gt;Patil, I. (2021). Visualizations with statistical details: The
‚Äòggstatsplot‚Äô approach. Journal of Open Source Software, 6(61), 3167, &lt;a
href="doi:10.21105/joss.03167"
class="uri"&gt;doi:10.21105/joss.03167&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R Core Team (2022). R: A language and environment for statistical
computing. R Foundation for Statistical Computing, Vienna, Austria. URL
&lt;a href="https://www.R-project.org/"
class="uri"&gt;https://www.R-project.org/&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Wickham et al., (2019). Welcome to the tidyverse. Journal of Open
Source Software, 4(43), 1686, &lt;a
href="https://doi.org/10.21105/joss.01686"
class="uri"&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can also use parts of &lt;code&gt;sessionInfo()&lt;/code&gt;, but why would
you? ü§ì&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_system()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Analyses were conducted using the R Statistical language (version
4.1.3; R Core Team, 2022) on macOS Big Sur/Monterey 10.16&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report_packages()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;flextable (version 0.7.0; David Gohel, 2022), Rcpp (version 1.0.8.3;
Dirk Eddelbuettel and Romain Francois, 2011), Matrix (version 1.4.1;
Douglas Bates, Martin Maechler and Mikael Jagan, 2022), lme4 (version
1.1.29; Douglas Bates et al., 2015), ISLR (version 1.4; Gareth James et
al., 2021), rstanarm (version 2.21.3; Goodrich B et al., 2022), ggplot2
(version 3.3.6; Wickham. ggplot2: Elegant Graphics for Data Analysis.
Springer-Verlag New York, 2016.), stringr (version 1.4.0; Hadley
Wickham, 2019), forcats (version 0.5.1; Hadley Wickham, 2021), tidyr
(version 1.2.0; Hadley Wickham and Maximilian Girlich, 2022), readr
(version 2.1.2; Hadley Wickham, Jim Hester and Jennifer Bryan, 2022),
dplyr (version 1.0.9; Hadley Wickham et al., 2022), tibble (version
3.1.7; Kirill M√ºller and Hadley Wickham, 2022), purrr (version 0.3.4;
Lionel Henry and Hadley Wickham, 2020), sjPlot (version 2.8.10; L√ºdecke
D, 2021), report (version 0.5.1; Makowski et al., 2020), ggstatsplot
(version 0.9.3; Patil, 2021), R (version 4.1.3; R Core Team, 2022),
tidyverse (version 1.3.1.9000; Wickham et al., 2019)&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;cite_packages()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;David Gohel (2022). flextable: Functions for Tabular Reporting. R
package version 0.7.0. &lt;a
href="https://CRAN.R-project.org/package=flextable"
class="uri"&gt;https://CRAN.R-project.org/package=flextable&lt;/a&gt;, Dirk
Eddelbuettel and Romain Francois (2011). Rcpp: Seamless R and C++
Integration. Journal of Statistical Software, 40(8), 1-18, &lt;a
href="doi:10.18637/jss.v040.i08"
class="uri"&gt;doi:10.18637/jss.v040.i08&lt;/a&gt;., Douglas Bates, Martin
Maechler and Mikael Jagan (2022). Matrix: Sparse and Dense Matrix
Classes and Methods. R package version 1.4-1. &lt;a
href="https://CRAN.R-project.org/package=Matrix"
class="uri"&gt;https://CRAN.R-project.org/package=Matrix&lt;/a&gt;, Douglas
Bates, Martin Maechler, Ben Bolker, Steve Walker (2015). Fitting Linear
Mixed-Effects Models Using lme4. Journal of Statistical Software, 67(1),
1-48. &lt;a href="doi:10.18637/jss.v067.i01"
class="uri"&gt;doi:10.18637/jss.v067.i01&lt;/a&gt;., Gareth James, Daniela
Witten, Trevor Hastie and Rob Tibshirani (2021). ISLR: Data for an
Introduction to Statistical Learning with Applications in R. R package
version 1.4. &lt;a href="https://CRAN.R-project.org/package=ISLR"
class="uri"&gt;https://CRAN.R-project.org/package=ISLR&lt;/a&gt;, Goodrich B,
Gabry J, Ali I &amp;amp; Brilleman S. (2022). rstanarm: Bayesian applied
regression modeling via Stan. R package version 2.21.3 &lt;a
href="https://mc-stan.org/rstanarm"
class="uri"&gt;https://mc-stan.org/rstanarm&lt;/a&gt;., H. Wickham. ggplot2:
Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016.,
Hadley Wickham (2019). stringr: Simple, Consistent Wrappers for Common
String Operations. R package version 1.4.0. &lt;a
href="https://CRAN.R-project.org/package=stringr"
class="uri"&gt;https://CRAN.R-project.org/package=stringr&lt;/a&gt;, Hadley
Wickham (2021). forcats: Tools for Working with Categorical Variables
(Factors). R package version 0.5.1. &lt;a
href="https://CRAN.R-project.org/package=forcats"
class="uri"&gt;https://CRAN.R-project.org/package=forcats&lt;/a&gt;, Hadley
Wickham and Maximilian Girlich (2022). tidyr: Tidy Messy Data. R package
version 1.2.0. &lt;a href="https://CRAN.R-project.org/package=tidyr"
class="uri"&gt;https://CRAN.R-project.org/package=tidyr&lt;/a&gt;, Hadley
Wickham, Jim Hester and Jennifer Bryan (2022). readr: Read Rectangular
Text Data. R package version 2.1.2. &lt;a
href="https://CRAN.R-project.org/package=readr"
class="uri"&gt;https://CRAN.R-project.org/package=readr&lt;/a&gt;, Hadley
Wickham, Romain Fran√ßois, Lionel Henry and Kirill M√ºller (2022). dplyr:
A Grammar of Data Manipulation. R package version 1.0.9. &lt;a
href="https://CRAN.R-project.org/package=dplyr"
class="uri"&gt;https://CRAN.R-project.org/package=dplyr&lt;/a&gt;, Kirill M√ºller
and Hadley Wickham (2022). tibble: Simple Data Frames. R package version
3.1.7. &lt;a href="https://CRAN.R-project.org/package=tibble"
class="uri"&gt;https://CRAN.R-project.org/package=tibble&lt;/a&gt;, Lionel Henry
and Hadley Wickham (2020). purrr: Functional Programming Tools. R
package version 0.3.4. &lt;a
href="https://CRAN.R-project.org/package=purrr"
class="uri"&gt;https://CRAN.R-project.org/package=purrr&lt;/a&gt;, L√ºdecke D
(2021). &lt;em&gt;sjPlot: Data Visualization for Statistics in
SocialScience&lt;/em&gt;. R package version 2.8.10, &amp;lt;URL:&lt;a
href="https://CRAN.R-project.org/package=sjPlot"
class="uri"&gt;https://CRAN.R-project.org/package=sjPlot&lt;/a&gt;&amp;gt;.,
Makowski, D., Ben-Shachar, M.S., Patil, I. &amp;amp; L√ºdecke, D. (2020).
Automated Results Reporting as a Practical Tool to Improve
Reproducibility and Methodological Best Practices Adoption. CRAN.
Available from &lt;a href="https://github.com/easystats/report"
class="uri"&gt;https://github.com/easystats/report&lt;/a&gt;. doi: ., Patil, I.
(2021). Visualizations with statistical details: The ‚Äòggstatsplot‚Äô
approach. Journal of Open Source Software, 6(61), 3167, &lt;a
href="doi:10.21105/joss.03167" class="uri"&gt;doi:10.21105/joss.03167&lt;/a&gt;,
R Core Team (2022). R: A language and environment for statistical
computing. R Foundation for Statistical Computing, Vienna, Austria. URL
&lt;a href="https://www.R-project.org/"
class="uri"&gt;https://www.R-project.org/&lt;/a&gt;., Wickham et al., (2019).
Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686,
&lt;a href="https://doi.org/10.21105/joss.01686"
class="uri"&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="further-readings-and-references"&gt;Further readings and
references&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://easystats.github.io/report/index.html"
class="uri"&gt;https://easystats.github.io/report/index.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All functions from {report} package: &lt;a
href="https://easystats.github.io/report/reference/index.html"
class="uri"&gt;https://easystats.github.io/report/reference/index.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;If you think, I missed something, please comment on it, and I‚Äôll
improve this tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you for learning!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5>f3e65c0dc4b8595156a58f45ad4de652</distill:md5>
      <category>videos</category>
      <category>statistics</category>
      <category>R package reviews</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-06-18-report</guid>
      <pubDate>Sun, 10 Jul 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-06-18-report/thumbnail_report.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {glmulti} find the best model!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-05-31-glmulti</link>
      <description>


&lt;h2 id="this-post-as-a-video"&gt;This post as a video&lt;/h2&gt;
&lt;p&gt;I recommend to watch a video first, because I highlight things I talk
about. It‚Äôs less then 14 minutes long.&lt;/p&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/Im293ClFen4" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id="why-do-we-need-glmulti"&gt;Why do we need {glmulti}?&lt;/h2&gt;
&lt;p&gt;The goal of ANY model is to explain a dependent variable by several
independent variables, sometimes called predictors. But which predictors
are useful(?) and how many should we include into our model(?), is
usually unknown. These questions are important, because if we take to
many predictors, we‚Äôll overfit the model and explain the noise in the
data instead of uncovering true relationships. While, if we include only
a few predictors into our model, we‚Äôll underfit the model and probably
miss some potentially important relationships. Thus, we need to find
&lt;strong&gt;THE BEST&lt;/strong&gt; model, with an &lt;strong&gt;optimal set of
predictors which explains maximum of our dependent variable, without
explaining the noise&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-05-31-glmulti/fit.png" /&gt;&lt;/p&gt;
&lt;h2 id="stepwise-variable-selection-approach"&gt;Stepwise variable
selection approach&lt;/h2&gt;
&lt;p&gt;One of the most common solutions for finding &lt;strong&gt;THE
BEST&lt;/strong&gt; model is &lt;strong&gt;a stepwise variable selection.&lt;/strong&gt;
But it‚Äôs not the best solution out there, and here is why. Stepwise
selection applies two main techniques: forwards and backwards selection.
Forwards selection starts with an empty model, adds one predictor,
compares two models, one with and another without this predictor, takes
the best model of the two, adds another predictor etc‚Ä¶ Backwards
selection starts with the most complicated model, which includes all
predictors and interactions, and reduces the number of terms one by one.
But there are two problems with it. First, &lt;strong&gt;forwards and
backwards approaches would often not converge to the same
model&lt;/strong&gt;, like in our example. And secondly, even if they converge
to the same model, this model might not be the optimal one (gray circle
on the picture below). These problems occur simply because stepwise
selection doesn‚Äôt look at &lt;strong&gt;all possible models at the same
time&lt;/strong&gt;. They just remove or add terms one by one, compare two
models, take the best model of the two, remove or add another term
etc..&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-05-31-glmulti/stepwise_problem.png" /&gt;&lt;/p&gt;
&lt;p&gt;Load all needed packages at once, to avoid interruptions.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(car)        # extracts model results
library(MASS)       # provides &amp;quot;birthwt&amp;quot; dataset
library(ISLR)       # provides &amp;quot;Wage&amp;quot; dataset
library(tictoc)     # checks running time
library(sjPlot)     # visualizes model results
library(glmulti)    # finds the BEST model
library(flextable)  # beautifies tables
library(tidyverse)  # provides a lot of useful stuff !!! 
library(performance)# checks and compares quality of models

theme_set(theme_light(base_size = 12)) # beautifies plots
theme_update(panel.grid.minor = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;# prepare selection
full_model &amp;lt;- glm(mpg ~ (hp + drat + wt + qsec + gear)^2, 
                 data = mtcars, family = gaussian)

null_model &amp;lt;- glm(mpg ~ 1, data = mtcars, family = gaussian)

# run stepwise selection
optimal_model_backward &amp;lt;- step(full_model, direction = &amp;quot;backward&amp;quot;,
                        scope = list(upper = full_model, lower = null_model))

optimal_model_forward &amp;lt;- step(null_model, direction = &amp;quot;forward&amp;quot;,
                        scope = list(upper = full_model, lower = null_model))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;# compare two final models
anova(optimal_model_backward, optimal_model_forward, test = &amp;quot;Chisq&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Analysis of Deviance Table

Model 1: mpg ~ hp + drat + wt + qsec + gear + hp:drat + hp:wt + hp:qsec + 
    hp:gear + drat:wt + drat:qsec + wt:qsec + wt:gear
Model 2: mpg ~ wt + hp + qsec + gear + wt:hp
  Resid. Df Resid. Dev Df Deviance Pr(&amp;gt;Chi)   
1        18      51.32                        
2        26     112.06 -8  -60.743  0.00638 **
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;compare_performance(optimal_model_backward, optimal_model_forward)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# Comparison of Model Performance Indices

Name                   | Model |     AIC | AIC weights |     BIC | BIC weights |    R2 |  RMSE | Sigma
------------------------------------------------------------------------------------------------------
optimal_model_backward |   glm | 135.927 |       0.989 | 157.913 |       0.203 | 0.954 | 1.266 | 1.689
optimal_model_forward  |   glm | 144.919 |       0.011 | 155.179 |       0.797 | 0.900 | 1.871 | 2.076&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="brute-force-approach-with-glmulti"&gt;‚ÄúBrute force‚Äù approach with
{glmulti}&lt;/h2&gt;
&lt;p&gt;In contrast, {glmulti} R package builds &lt;strong&gt;all possible models
with all possible combinations of predictors and, optionally, even their
pairwise interactions&lt;/strong&gt;. Such approach was called ‚Äúbrute
force‚Äù.&lt;/p&gt;
&lt;p&gt;{glmulti} then compares the amount of useful information models
provide. Such model comparison is done with the help of information
criteria (IC), for example Akaike‚Äôs IC (aic) or Bayesian IC (bic).
Information criteria are used instead of other metrics, such as &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt;, because they show the ‚Äúfitness‚Äù of
the model, where this fitness is penalized by the number of predictors a
model incorporates. In contrast to information criteria, &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt; will always increase with the
increasing number of terms and will eventually overfit the model. And as
mentioned before, an overfitted model is bad, because it describes the
noise rather than genuine relationships between variables. Consequently,
we can‚Äôt trust the coefficients and p-values of overfitted models.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-05-31-glmulti/bic_vs_r_squared.jpeg" style="width:50.0%" /&gt;&lt;/p&gt;
&lt;p&gt;This picture originates from &lt;a
href="https://www.igi-global.com/gateway/chapter/235052"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;But that‚Äôs not all, overfitting produces another problem. Each sample
has its own unique quirks. Consequently, overfitted model that fits the
random quirks of one sample is unlikely to fit the random quirks of
another sample. That makes overfitted model less generalizable outside
the original dataset, and therefore less useful.&lt;/p&gt;
&lt;p&gt;That‚Äôs why we need to create &lt;strong&gt;all possible models&lt;/strong&gt;,
instead of using stepwise selection, and we need to compare models using
&lt;strong&gt;Information Criteria&lt;/strong&gt;, instead of &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt;. And while ‚ÄúBrute force‚Äù approach is
great, the number of models to be considered can easily become
exorbitant. However, there are several possibilities to reduce the
number of models and to decrease calculation time. Let‚Äôs get into the
Code and see how to do that.&lt;/p&gt;
&lt;h2 id="how-to-compute-glmulti-to-find-the-best-model"&gt;How to compute
glmulti to find the best model&lt;/h2&gt;
&lt;p&gt;The code is similar to any other model, you use in R:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;first you have the &lt;strong&gt;formula&lt;/strong&gt; with the dependent
variable on the left side of the tilde (~), and all possible predictors
on the right side of the tilde. For this example we‚Äôll study the salary
of 3000 american workers with 5 predictors: jobclass, education, age,
health and health-insurance&lt;/li&gt;
&lt;li&gt;then we‚Äôll tell R which &lt;strong&gt;dataset&lt;/strong&gt; to use. In this
case we‚Äôll use the ‚ÄúWage‚Äù dataset from ISLR package&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;crit&lt;/strong&gt; specifies the &lt;strong&gt;Information
Criterion&lt;/strong&gt; to be used. Default is the Akaike IC (aic). Other
options are the Bayesian IC (bic), quasi-AIC for overdispersed or count
data (qaic and qaicc) and the small-sample corrected AIC (aicc), which I
personally prefer, because for big samples it always gets the same
result as Akaike‚Äôs IC, while with small samples it performs better&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;level&lt;/strong&gt; - argument is important! It specifies weather
all possible models supposed to be build without interactions (level =
1) or with interactions (level = 2)&lt;/li&gt;
&lt;li&gt;argument - &lt;strong&gt;method&lt;/strong&gt; - explores the candidate set of
models. Method = ‚Äúd‚Äù counts the number of candidate models without
calculating anything. For our example of 5 predictors we‚Äôll have 32
models without interactions and 1921 models with interactions. If method
= ‚Äúh‚Äù, an &lt;strong&gt;exhaustive screening&lt;/strong&gt; is undertaken, which
means that all possible models will be created. If method = ‚Äúg‚Äù, the
genetic algorithm is employed (recommended for large candidate
sets)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;glmulti(wage   ~ jobclass + education + age + health + health_ins,
        data   = Wage, 
        crit   = aicc,       # AICC corrected AIC for small samples
        level  = 1,          # 2 with interactions, 1 without  
        method = &amp;quot;d&amp;quot;,        # &amp;quot;d&amp;quot;, or &amp;quot;h&amp;quot;, or &amp;quot;g&amp;quot;
        family = gaussian, 
        fitfunction = glm,   # Type of model (LM, GLM etc.)
        confsetsize = 100)   # Keep 100 best models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Initialization...
TASK: Diagnostic of candidate set.
Sample size: 3000
4 factor(s).
1 covariate(s).
0 f exclusion(s).
0 c exclusion(s).
0 f:f exclusion(s).
0 c:c exclusion(s).
0 f:c exclusion(s).
Size constraints: min =  0 max = -1
Complexity constraints: min =  0 max = -1
Your candidate set contains 32 models.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 32&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;glmulti(wage   ~ jobclass + education + age + health + health_ins,
        data   = Wage, 
        crit   = aicc,       # AICC corrected AIC for small samples
        level  = 2,          # 2 with interactions, 1 without  
        method = &amp;quot;d&amp;quot;,        # &amp;quot;d&amp;quot;, or &amp;quot;h&amp;quot;, or &amp;quot;g&amp;quot;
        family = gaussian, 
        fitfunction = glm,   # Type of model (LM, GLM, GLMER etc.)
        confsetsize = 100)   # Keep 100 best models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Initialization...
TASK: Diagnostic of candidate set.
Sample size: 3000
4 factor(s).
1 covariate(s).
0 f exclusion(s).
0 c exclusion(s).
0 f:f exclusion(s).
0 c:c exclusion(s).
0 f:c exclusion(s).
Size constraints: min =  0 max = -1
Complexity constraints: min =  0 max = -1
Your candidate set contains 1921 models.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 1921&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;you then specify the distribution &lt;strong&gt;family&lt;/strong&gt; and
the&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fitfunction&lt;/strong&gt;, where any function similar to
&lt;strong&gt;lm, glm or glmer&lt;/strong&gt; can be used&lt;/li&gt;
&lt;li&gt;lastly, &lt;strong&gt;confsetsize&lt;/strong&gt; argument allows you to keep a
particular number of the best models, so called - &lt;strong&gt;confident set
of best models&lt;/strong&gt;. One hundred - is a default value.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, now let‚Äôs run the exhaustive algorithm and see how much time it
takes to compute 1921 regressions and to find the BEST model for our 5
predictors with interactions. ‚Äútic()‚Äù and ‚Äútoc()‚Äù functions from
{tictoc} package would record running time for us.&lt;/p&gt;
&lt;p&gt;Fortunately, the exhaustive method took only 19 seconds. Not bad at
all, if you ask me. However, I usually have way more then five
predictors, which could cause performance problems. That‚Äôs why we need
to talk about the‚Ä¶&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tic()

h_model &amp;lt;- glmulti(wage ~ jobclass + education + age + health + health_ins,
          data   = Wage, 
          crit   = aicc,       # AICC corrected AIC for small samples
          level  = 2,          # 2 with interactions, 1 without  
          method = &amp;quot;h&amp;quot;,        # &amp;quot;d&amp;quot;, or &amp;quot;h&amp;quot;, or &amp;quot;g&amp;quot;
          family = gaussian, 
          fitfunction = glm,   # Type of model (LM, GLM, GLMER etc.)
          confsetsize = 100)   # Keep 100 best models

toc() # 19 sec elapsed: 1921 models &lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="performance-impovement-techniques"&gt;Performance impovement
techniques&lt;/h2&gt;
&lt;h3 id="remove-unnecessary-terms"&gt;1. Remove unnecessary terms&lt;/h3&gt;
&lt;p&gt;And the first one is to remove all unnecessary predictors or
interactions. For example a &lt;em&gt;weight&lt;/em&gt; and &lt;em&gt;body mass index
(BMI)&lt;/em&gt; provide very similar information - the statisticians would
say - they are highly multicollinear. Anyway, if both, &lt;em&gt;weight&lt;/em&gt;
and &lt;em&gt;BMI&lt;/em&gt; are included, they would dramatically increase the
number of models without providing any value. Check this out, adding
only two additional categorical predictors (maritl &amp;amp; region) into
the Wage model above increases the number of models to over 2.5 millions
(2604485 to be exact, see below). And while it‚Äôs unimaginable to run so
many models in our life time, &lt;strong&gt;genetic algorithm&lt;/strong&gt;
provides a solution for it.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;glmulti(wage ~ jobclass + education + age + health + health_ins + maritl + region,
        data   = Wage, 
        crit   = aicc,       # AICC corrected AIC for small samples
        level  = 2,          # 2 with interactions, 1 without  
        method = &amp;quot;d&amp;quot;,        # &amp;quot;d&amp;quot;, or &amp;quot;h&amp;quot;, or &amp;quot;g&amp;quot;
        family = gaussian, 
        fitfunction = glm,   # Type of model (LM, GLM, GLMER etc.)
        confsetsize = 100,
        plotty=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Initialization...
TASK: Diagnostic of candidate set.
Sample size: 3000
6 factor(s).
1 covariate(s).
0 f exclusion(s).
0 c exclusion(s).
0 f:f exclusion(s).
0 c:c exclusion(s).
0 f:c exclusion(s).
Size constraints: min =  0 max = -1
Complexity constraints: min =  0 max = -1
Your candidate set contains 2604485 models.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 2604485&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="use-genetic-algorithm"&gt;2. Use genetic algorithm&lt;/h3&gt;
&lt;p&gt;Particularly, having 6 numeric predictors with interactions, the
‚Äúbrute force‚Äù approach needs almost 3 hours, while genetic algorithm
runs only 40-80 seconds and produces almost identical results (with
sometimes slightly worse IC value).&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tic()

test_h &amp;lt;- glmulti(mpg ~ hp + drat + wt + qsec + gear, 
                 data   = mtcars, 
                 method = &amp;quot;h&amp;quot;,       # Exhaustive approach
                 crit   = aic,      # AICC corrected AIC for small samples
                 level  = 2,         # 2 with interactions, 1 without
                 family = gaussian,
                 fitfunction = glm,  # Type of model (LM, GLM, GLMER etc.)
                 confsetsize = 100)  # Keep 100 best models

toc() # 32768 models &amp;quot;h&amp;quot; takes 104-109 seconds
# 6 numeric predictors with interactions produces 2.097.152 models, and &amp;quot;h&amp;quot; method takes 9715.466 seconds or ca. 2.7 hours

tic()

test_g &amp;lt;- glmulti(mpg ~ hp + drat + wt + qsec + gear, 
                 data   = mtcars, 
                 method = &amp;quot;g&amp;quot;,       # genetic algorithm approach
                 crit   = aic,      # AICC corrected AIC for small samples
                 level  = 2,         # 2 with interactions, 1 without
                 family = gaussian,
                 fitfunction = glm,  # Type of model (LM, GLM, GLMER etc.)
                 confsetsize = 100)  # Keep 100 best models

toc() # 32768 models &amp;quot;g&amp;quot; takes 40-59 seconds
# 6 numeric predictors with interactions produces 2.097.152 models, and &amp;quot;g&amp;quot; method takes 40-80 seconds or ca. 1 minute&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, if genetic algorithm is sooo cool, why not use genetic algorithm
all the time? Well, interestingly enough, with categorical predictors,
having a lot of categories, genetic algorithms may perform slower as
compared to the exhaustive one. For instance, our Wage-model, which has
lots of categorical predictors took only 19 second with the exhaustive
screening, while needed 117 seconds till genetic algorithm converged,
so, almost 6 times longer. Moreover, genetic algorithm might have
convergence problem and might run indefinitely long, without you having
any idea of WHEN, or IF it ever stops. And lastly, exhaustive method
almost always delivers better IC values. That‚Äôs why I‚Äôd recommend to
&lt;strong&gt;produce all possible models (aka. using exhaustive screening,
aka. applying ‚Äúbrute force‚Äù approach) whenever possible&lt;/strong&gt; and
only use genetic algorithm for a high number of numeric predictors.&lt;/p&gt;
&lt;h3 id="specify-marginality-and-exclude-arguments-optional"&gt;3. Specify
‚Äúmarginality‚Äù and ‚Äúexclude‚Äù arguments (optional) ‚Äì&amp;gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;marginality = TRUE&lt;/strong&gt;, argument considers only
marginal models. That would reduce the number of model from 2604485 to
2350602. I did not really understand what the martinality exactly does,
that is why I just prefer to leave it out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Argument &lt;strong&gt;exclude&lt;/strong&gt; excludes (main effects or
interactions) from the candidate models, e.g.¬†c(‚Äúmass:height‚Äù) ‚Ä¶ it
somehow did not work in my code and I could not find out why. I hope it
will work on your machine!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;using multiple cores while computing might help.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="what-the-hell-is-the-best-model-then"&gt;What the hell is THE BEST
model then ???&lt;/h2&gt;
&lt;p&gt;By the way, remember, in the beginning of the video I said, that
stepwise selection is not the best method, implying that {glmulti}
approach is better? Well, let‚Äôs compare the results of exhaustive and
genetic algorithms, to the results of forward and backwards selections
and see which is a &lt;strong&gt;TRULY BEST&lt;/strong&gt; model:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;optimal_model_glmulti_exhaustive &amp;lt;- test_h@objects[[1]]
optimal_model_glmulti_genetic    &amp;lt;- test_g@objects[[1]]
compare_performance(optimal_model_glmulti_exhaustive, optimal_model_glmulti_genetic, optimal_model_backward, optimal_model_forward)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# Comparison of Model Performance Indices

Name                             | Model |     AIC | AIC weights |     BIC | BIC weights |    R2 |  RMSE | Sigma
----------------------------------------------------------------------------------------------------------------
optimal_model_glmulti_exhaustive |   glm | 134.734 |       0.391 | 146.460 |       0.496 | 0.932 | 1.547 | 1.750
optimal_model_glmulti_genetic    |   glm | 134.734 |       0.391 | 146.460 |       0.496 | 0.932 | 1.547 | 1.750
optimal_model_backward           |   glm | 135.927 |       0.215 | 157.913 |       0.002 | 0.954 | 1.266 | 1.689
optimal_model_forward            |   glm | 144.919 |       0.002 | 155.179 |       0.006 | 0.900 | 1.871 | 2.076&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;optimal_model_glmulti_exhaustive$formula&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mpg ~ 1 + wt + qsec + gear + drat:hp + qsec:wt + gear:wt
&amp;lt;environment: 0x7fafbe688568&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;optimal_model_glmulti_genetic$formula&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mpg ~ 1 + wt + qsec + gear + drat:hp + qsec:wt + gear:wt
&amp;lt;environment: 0x7fafbc8424d0&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;optimal_model_backward$formula&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mpg ~ hp + drat + wt + qsec + gear + hp:drat + hp:wt + hp:qsec + 
    hp:gear + drat:wt + drat:qsec + wt:qsec + wt:gear
&amp;lt;environment: 0x7fb00892df10&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;optimal_model_forward$formula&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mpg ~ wt + hp + qsec + gear + wt:hp
&amp;lt;environment: 0x7fb00892df10&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see {glmulti} approach produced lower AIC and much lower
BIC Information criteria, and interestingly enough, the &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt; produced by {glmulti} is right in
between the &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt;s of forwards and
backwards selections, suggesting that {glmulti} models are neither
underfitted not overfitted. Moreover, in our example both exhaustive and
genetic algorithms have identical result (will not always be the case)
and showed three interactions (drat:hp + qsec:wt + gear:wt) to be
important, while backwards selection found 8 interactions to be
important, which to me sound like overfitting, which is in line with
it‚Äôs highest &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt;, and forwards
selection found only one interaction, which looks like underfitting,
which is in line with it‚Äôs lowest &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;So, I hope I could convince you that &lt;strong&gt;{glmulti} approach is
superior to the stepwise selection&lt;/strong&gt; approach and produces a
&lt;strong&gt;truly BEST model&lt;/strong&gt;.&lt;/p&gt;
&lt;!-- ```{r eval=FALSE} --&gt;
&lt;!-- tic() --&gt;
&lt;!-- g_model &lt;- glmulti(wage ~ jobclass + education + age + health + health_ins, --&gt;
&lt;!--           data   = Wage,  --&gt;
&lt;!--           crit   = aicc,       # AICC corrected AIC for small samples --&gt;
&lt;!--           level  = 2,          # 2 with interactions, 1 without   --&gt;
&lt;!--           method = "g",        # "d", or "h", or "g" --&gt;
&lt;!--           family = gaussian,  --&gt;
&lt;!--           fitfunction = glm,   # Type of model (LM, GLM, GLMER etc.) --&gt;
&lt;!--           confsetsize = 100)   # Keep 100 best models --&gt;
&lt;!-- toc() # 117 sec elapsed: After 440 generations:  --&gt;
&lt;!-- ``` --&gt;
&lt;h2 id="some-exotic-applications-glmer-or-multinom"&gt;Some exotic
applications: GLMER or multinom&lt;/h2&gt;
&lt;p&gt;And while {glmulti} works fine with the classic functions like LM and
GLM, it can also fit some exotic models, such as ‚Äúmultinomial‚Äù models
via Neural Networks from {nnet} package.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(nnet)

multinom_glmulti &amp;lt;- glmulti(
  education ~ wage + jobclass + health, 
  data   = Wage, 
  level  = 2, 
  method = &amp;quot;h&amp;quot;
  fitfunction = multinom)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the predictions of the best multinomial model:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot(effects::allEffects(multinom_glmulti@objects[[1]]),
     lines = list(multiline = T),
     confint = list(style = &amp;quot;auto&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file954a2ccea02_files/figure-html/unnamed-chunk-14-1.png" width="1344" /&gt;&lt;/p&gt;
&lt;p&gt;And lastly, despite the fact there is no straightforward fitting
function for the mixed-effects models, such as GLMER from {lme4}
package, we can easily write our own wrapper-function and use it inside
of {glmulti}:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;glmer.glmulti&amp;lt;-function(formula, data, random = &amp;quot;&amp;quot;, ...){
   glmer(paste(deparse(formula),random),
         data    = data, REML = F, ...)
}

mixed_model &amp;lt;- glmulti(
  y = response ~ predictor_1 + predictor_2 + predictor_3,
  random  = &amp;quot;+(1|random_effect)&amp;quot;,
  crit    = aicc,
  data    = data,
  family  = binomial,
  method  = &amp;quot;h&amp;quot;,
  fitfunc = glmer.glmulti,
  marginality = F,
  level   = 2 )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let‚Äôs have a look at the results of our BEST model and interpret
them.&lt;/p&gt;
&lt;h2 id="extract-results"&gt;Extract results&lt;/h2&gt;
&lt;p&gt;The output of a {glmulti} analysis is an object containing the
&lt;strong&gt;confidence set of models (100 best models by default)&lt;/strong&gt;.
Standard R regression functions like ‚Äúsummary()‚Äù, ‚Äúcoef()‚Äù or ‚Äúplot()‚Äù
can all be used to make a multi-model inference. But let‚Äôs start with
the brief summary of the results which can be obtained with via
‚Äúprint()‚Äù command:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;print(h_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;glmulti.analysis
Method: h / Fitting: glm / IC used: aicc
Level: 2 / Marginality: FALSE
From 100 models:
Best IC: 29793.4306133546
Best model:
[1] &amp;quot;wage ~ 1 + jobclass + education + health + health_ins + age + &amp;quot;  
[2] &amp;quot;    education:jobclass + health_ins:education + education:age + &amp;quot;
[3] &amp;quot;    health:age + health_ins:age&amp;quot;                                 
Evidence weight: 0.0786680339413555
Worst IC: 29801.3206286612
6 models within 2 IC units.
74 models to reach 95% of evidence weight.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;‚Ä¶ were we see the most important information, such as fitting
function, the information criteria used to rank the models, the formula
of the best model and even the number of models which as good as the
best model. There are 6 models, which we can also see if we plot our
object:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot(h_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file954a2ccea02_files/figure-html/unnamed-chunk-18-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;This plot shows the IC values for all 100 models from the confidence
set. A horizontal line separates 6 best models, that are less than 2 IC
units away from &lt;strong&gt;THE BEST&lt;/strong&gt; model. But what predictors and
interactions do those 6 models contain? Using {weightable} function, we
can easily display them:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;weightable(h_model)[1:6,] %&amp;gt;% 
  regulartable() %&amp;gt;%       # beautifying tables
  autofit()&lt;/code&gt;&lt;/pre&gt;
&lt;template id="e26e37f8-8c3a-4e3c-8c51-1c39e9771f29"&gt;&lt;style&gt;
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
&lt;/style&gt;&lt;div class="tabwid"&gt;&lt;style&gt;.cl-eee2d51a{}.cl-eedbeca0{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-eedc0c08{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-eedc0c12{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-eedc4c04{width:69.5pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-eedc4c18{width:865.7pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-eedc4c19{width:78.6pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-eedc4c22{width:865.7pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-eedc4c23{width:69.5pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-eedc4c2c{width:78.6pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-eedc4c36{width:69.5pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-eedc4c37{width:865.7pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-eedc4c40{width:78.6pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}&lt;/style&gt;&lt;table class='cl-eee2d51a'&gt;
&lt;thead&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-eedc4c37"&gt;&lt;p class="cl-eedc0c08"&gt;&lt;span class="cl-eedbeca0"&gt;model&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c36"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;aicc&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c40"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;weights&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-eedc4c18"&gt;&lt;p class="cl-eedc0c08"&gt;&lt;span class="cl-eedbeca0"&gt;wage ~ 1 + jobclass + education + health + health_ins + age + education:jobclass + health_ins:education + education:age + health:age + health_ins:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c04"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;29,793.43&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c19"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;0.07866803&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-eedc4c18"&gt;&lt;p class="cl-eedc0c08"&gt;&lt;span class="cl-eedbeca0"&gt;wage ~ 1 + jobclass + education + health + health_ins + age + education:jobclass + health_ins:education + education:age + health:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c04"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;29,793.68&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c19"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;0.06952606&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-eedc4c18"&gt;&lt;p class="cl-eedc0c08"&gt;&lt;span class="cl-eedbeca0"&gt;wage ~ 1 + jobclass + education + health_ins + age + education:jobclass + health_ins:education + education:age + health:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c04"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;29,794.40&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c19"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;0.04836431&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-eedc4c18"&gt;&lt;p class="cl-eedc0c08"&gt;&lt;span class="cl-eedbeca0"&gt;wage ~ 1 + jobclass + education + health_ins + age + education:jobclass + health_ins:education + education:age + health:age + health_ins:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c04"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;29,794.43&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c19"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;0.04776916&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-eedc4c18"&gt;&lt;p class="cl-eedc0c08"&gt;&lt;span class="cl-eedbeca0"&gt;wage ~ 1 + jobclass + education + health + health_ins + age + education:jobclass + health_ins:education + jobclass:age + education:age + health:age + health_ins:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c04"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;29,795.31&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c19"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;0.03070167&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-eedc4c22"&gt;&lt;p class="cl-eedc0c08"&gt;&lt;span class="cl-eedbeca0"&gt;wage ~ 1 + jobclass + education + health + health_ins + age + education:jobclass + health_ins:jobclass + health_ins:education + education:age + health:age + health_ins:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c23"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;29,795.36&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-eedc4c2c"&gt;&lt;p class="cl-eedc0c12"&gt;&lt;span class="cl-eedbeca0"&gt;0.02990738&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/template&gt;
&lt;div class="flextable-shadow-host" id="971481dd-10fb-4b46-9aad-5026f8edad93"&gt;&lt;/div&gt;
&lt;script&gt;
var dest = document.getElementById("971481dd-10fb-4b46-9aad-5026f8edad93");
var template = document.getElementById("e26e37f8-8c3a-4e3c-8c51-1c39e9771f29");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
&lt;/script&gt;

&lt;p&gt;Here we see the formulas, Information Criteria and the Akaike weights
of our 6 best models. The Akaike weight for a particular model shows the
probability that the model is the best model out of all models
considered. To say it in a simple lingo - the model with the highest
weight minimizes the loss of information. So, while the ‚Äúbest‚Äù model has
the highest weight, its weight in this example is not substantially
larger than that of the second model (and also the third, fourth, and so
on). So, we shouldn‚Äôt be all too certain here that the top model is
really &lt;strong&gt;the best model&lt;/strong&gt; in the set. Several models are
almost equally plausible. So, &lt;strong&gt;which model should we take
then?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If all 6 models are great, but have different combinations of
predictors and interactions, figuring out which terms are important may
help to choose the best model. Fortunately for us, the
&lt;code&gt;plot()&lt;/code&gt; command with &lt;code&gt;type="s"&lt;/code&gt; argument displays
the relative importance of model terms across all models. The importance
value for a particular predictor or interaction is equal to the sum of
the weights for the models in which the variable appears. So, &lt;strong&gt;a
variable that shows up in lots of models with large weights will receive
a high importance value&lt;/strong&gt;. A vertical line is drawn at 80% (where
terms to the right of the line are part of 80% of the models), which is
sometimes used as a cutoff to differentiate between very important and
less important variables. This threshold is somewhat arbitrary though,
so that we are free to set it at ‚Ä¶ let‚Äôs say 50% and include all the
predictors and interactions with the importance above 50% into the final
model.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot(h_model, type = &amp;quot;s&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file954a2ccea02_files/figure-html/unnamed-chunk-20-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;Interestingly, the very first model contains the
&lt;em&gt;age:health_ins&lt;/em&gt; interaction, which has ca. 50% importance. And
it would be totally fine to go with that. But, since we have so many
terms with the importance around 80%, I am happy to use only those,
including &lt;em&gt;education:health_insurance&lt;/em&gt; interaction and predictor
&lt;em&gt;health&lt;/em&gt;, because they are far enough from the rest. And if I
look at 6 best models, I‚Äôll see that the second model has exactly those
terms. The third model is a bit worse because it does not contain
variable health, but since health is part of the most important
interaction - &lt;em&gt;age:health&lt;/em&gt;, I‚Äôd prefer to include it. So, now we
did not blindly trust the algorithm and took it‚Äôs &lt;strong&gt;BEST
MODEL&lt;/strong&gt;, but examined the results carefully and made a grounded
decision to take the second model as &lt;strong&gt;OUR BEST
MODEL&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Now, we can easily interpret and visualize and check assumptions of
&lt;strong&gt;OUR BEST&lt;/strong&gt; model as we always do:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;best_model &amp;lt;- h_model@objects[[2]]

car::Anova(best_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Analysis of Deviance Table (Type II tests)

Response: wage
                     LR Chisq Df Pr(&amp;gt;Chisq)    
jobclass                 4.91  1   0.026764 *  
education              626.21  4  &amp;lt; 2.2e-16 ***
health                  28.16  1  1.117e-07 ***
health_ins             158.79  1  &amp;lt; 2.2e-16 ***
age                     90.94  1  &amp;lt; 2.2e-16 ***
jobclass:education      16.14  4   0.002838 ** 
education:health_ins    10.22  4   0.036890 *  
education:age           12.11  4   0.016572 *  
health:age              10.13  1   0.001459 ** 
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot_model(best_model, type = &amp;quot;int&amp;quot;) %&amp;gt;% 
  plot_grid()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file954a2ccea02_files/figure-html/unnamed-chunk-21-1.png" width="1440" /&gt;&lt;/p&gt;
&lt;p&gt;And if you want to learn &lt;strong&gt;how to test ALL model-assumptions
using only one function&lt;/strong&gt;, check out {performance} package:&lt;/p&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/BNTn_f43U04" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id="problems"&gt;Problems&lt;/h2&gt;
&lt;p&gt;So, while {glmulti} is an amazing package, but it is not perfect and
here are three things I found challenging:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;rJava package needed. If you can‚Äôt easily install rJava package
from RStudio, chances are your computed does not have Java installed.
Doing this can take some time and nerves.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;some arguments are poorly described (e.g.¬†‚Äúmarginality‚Äù), or
simply do not work (e.g.¬†‚Äúexclude‚Äù). Please, let me know in the comments
below, if you managed to use ‚Äúexclude‚Äù.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;and while the &lt;code&gt;coef()&lt;/code&gt; and &lt;code&gt;predict()&lt;/code&gt;
commands are useful multi-model inference tools for models without
interactions and only with numeric predictors and could provide
multi-model averaged estimates, confidence intervals and predictions, I
find them less intuitive for the models with several interactions and
with many categorical predictors.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="further-readings-and-references"&gt;Further readings and
references&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.jstatsoft.org/article/view/v034i12"
class="uri"&gt;https://www.jstatsoft.org/article/view/v034i12&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a
href="https://cran.r-project.org/web/packages/glmulti/glmulti.pdf"
class="uri"&gt;https://cran.r-project.org/web/packages/glmulti/glmulti.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.igi-global.com/gateway/chapter/235052"
class="uri"&gt;https://www.igi-global.com/gateway/chapter/235052&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;If you think, I missed something, please comment on it, and I‚Äôll
improve this tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you for learning!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5>e293af68b10d93947ec753cf0794c593</distill:md5>
      <category>videos</category>
      <category>statistics</category>
      <category>machine learning</category>
      <category>R package reviews</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-05-31-glmulti</guid>
      <pubDate>Sat, 18 Jun 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-05-31-glmulti/thumbnail_glmulti.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Tidy Data and Why We Need It!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata</link>
      <description>Tidy data are easy to manipulate, visualise and analyse, while messy data always interrupts the analysis and invates mistakes. So, tidying up data before analysis pays off a great deal in the long term. In this post you'll learn how do we tidy up data.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata</guid>
      <pubDate>Mon, 23 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata/tidydata_2.jpeg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | ANOVA (One-Way ) | Fisher's, Welch's, Bayesian, Robust</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-03-anova</link>
      <description>How does education influence our salary? ANOVA which is just the abbreviation for Analysis Of Variances you see on the thumbnail answeres this question with Frequentists and Bayesian tests. It also privides two different effect sizes, compares education levels pairwisely and even corrects p-values for multiple comparisons. ALL OF THAT is done by this simple command. So, in this blog-post you'll learn how to produce the statistically rich plot, you'll understand when to conduct Welch's ANOVA and when Fisher's ANOVA and you'll know how to interpret every little detail on this plot. Lets get into it.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-03-anova</guid>
      <pubDate>Mon, 16 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-03-anova/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Kruskal-Wallis test | How to conduct, visualize, interpret &amp; more üòâ</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-13-kw</link>
      <description>If we have ordinal or not-normally distributed data, ANOVA might produce a wrong result. That's why we need Kruskal-Wallis test. Kruskal-Wallis test you see on the screen answers two question (1) whether at least one group is different from other groups and (2) between which groups exactly this difference is. So, let's learn how to get and interpret all these results.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-13-kw</guid>
      <pubDate>Mon, 16 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-13-kw/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Repeated Measures ANOVA (One-Way) | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova</link>
      <description>Can sport increase our selfesteem? Well, one experiment measured self-esteem of 10 people on three different time points and used Repeated Measures ANOVA to answer this question. So, let's learn how to produce this statistically rich plot using only one simple command and how to interpret all these results.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova</guid>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Cochran‚Äôs Q Test + Pairwise McNemar Tests (post-hoc)</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-04-cochran</link>
      <description>Cochran test is an extension of the McNemar test for comparing MORE than two PAIRED categorical samples in which the same individuals appear in each sample. If Cochran test is significant, we'd need to compare samples among each other pairwisely with McNemar tests. So, let's do that.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-04-cochran</guid>
      <pubDate>Wed, 20 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-04-cochran/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Mann-Whitney U Test = Wilcoxon Rank Sum Test | How to conduct, visualise &amp; interpret ü•≥ What happens if we use a wrong test üò±</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest</link>
      <description>Comparing two groups with not-normally disctributed or ordinal data is the reason we need Mann-Whitney U Test instead of t-Test. So, today we'll learn (1) how to conduct and visualize Mann-Whitney U Test you saw on the thumbnail with one simple command, (2) how to interpret all statistical results on that plot and (3) why this test is sometimes called Wilcoxon Rank Sum Test and why we shouldn't use this name</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest</guid>
      <pubDate>Sat, 16 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Correlation Matrix | Danger or opportunity?</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr</link>
      <description>Having several numeric variables, we often wanna know which of them are correlated and how. Correlation Matrix seems to be a good solution for it. But drawing conclusions from plain correlation coeffitients and p-values is dangerous, if we don't visualize the data. Let's learn a better way to produce a correlation matrix.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr</guid>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | Two-Samples t-Test | Student's &amp; Welch's | How to conduct, visualise, interpret | What happens if we use a wrong test üò±</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-11-ttest</link>
      <description>Two-samples t-test can answer useful questions, for example - where can we get more money, working in a factory or in the IT-industry? So, let's learn (1) how to make sure t-test is a CORRECT test for our data, (2) how to get all these results with one simple command, (3) how to interpret all these results and (4) finally see what happens if we choose a wrong test.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-11-ttest</guid>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-11-ttest/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Paired Samples t-Test | How to conduct, visualise and interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr</link>
      <description>Can one week of training significantly improve your number of sit-ups? Well, Paired t-Test can answer this question by comparing your performance Before and After this week. So, let's learn how to produce this statistically rich plot using only one simple command, how to interpret all these results and see what happens if we use a wrong test.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr</guid>
      <pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | McNemar Test | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar</link>
      <description>If you need to compare two PAIRED categorical samples, McNemar test is a correct choise for you. Though, people often use Chi-Square test instead. Thus, in this blog-post we'll first conduct, visualize and interpret McNemac test you see on the picture to your right using only one simple command and then see what happens if we use Chi-Square test for paired data.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar</guid>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Friedman Test | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-02-08-friedman</link>
      <description>The Friedman Test is a non-parametric brother of Repeated Measures ANOVA, which does much better job when data is not-normally distributed (which happens pretty often ;). Friedman test is also superior to Repeated Measures ANOVA when our data is ordinal (e.g., scales from 1 to 10). Friedman Test can also be a non-parametric father of the Paired Wilcoxon test, because it can compare more then two groups.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-02-08-friedman</guid>
      <pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-02-08-friedman/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Paired Samples Wilcoxon Signed Rank Test</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr</link>
      <description>Can a speed-reading exercise make you a faster reader? Well, Wilcoxon Signed Rank Test displayed here is a correct test to answer this question. So, in this video we'll learn how to choose a correct test and what happens if we use a wrong test, why Wilcoxon test is called Signed Rank and how to produce and interpret this statistically rich plot using only one simple command.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr</guid>
      <pubDate>Wed, 26 Jan 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Correlation Analysis in R | Pearson, Spearman, Robust, Bayesian | How to conduct, visualise and interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr</link>
      <description>Having two numeric variables, we often wanna know whether they are correlated and how. One simple command {ggscatterstats} can answer both questions by visualizing the data and conducting frequentists and bayesian correlation analysis at the same time. So, let's learn how to do that, how to interpret all those results and how to choose the right correlation method in the first place.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr</guid>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>One-sample Student‚Äôs t-test and One-sample Wilcoxon test: or how to compare your work to the work of others.</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others</link>
      <description>Imagine you get 7 out of 10 to-dos from your list done on average. Are you then more productive then others? One-sample t-test and One-sample Wilcoxon test can answer this question. So, in this blog-post you'll learn how to conduct and visualize these tests with only one simple command, how to interpret all these results and how to choose the right test in the first place. Let's get straight into it.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others</guid>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | Chi-Square Test | how to conduct, visualize &amp; interpret | + pairwise post-hoc tests</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r</link>
      <description>Chi-Square Test checks the independence between two categorical variables, where variables can have two or more categories. Need to do Chi-Square test? It can actually be done with only one line of code. There is no better way than {ggbarstats} function from {ggstatsplot} package üì¶. In this short blog-post you'll learn how to conduct, visualize and interpret Chi-Square test &amp; pairwise post-hoc tests in R.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r</guid>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R package reviews {dlookr} diagnose, explore and transform your data</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data</link>
      <description>Raw data need to be diagnosed for existing problems, explored for new hypotheses and repaired in order to increase data quality and output. The {dlookr} package makes these steps fast and easy. {dlookr} generates automated reports and performs compex operations, like imputing missing values or outliers, with simple functions. Moreover, {dlookr} collaborates perfectly with {tidyverse} packages, like {dplyr} and {ggplot2} to name just a few!</description>
      <category>EDA</category>
      <category>videos</category>
      <category>data wrangling</category>
      <category>R package reviews</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data</guid>
      <pubDate>Sat, 30 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data/dlookr_thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Deep Exploratory Data Analysis (EDA) in R</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress</link>
      <description>Exploratory Data Analysis is an important first step on the long way to the final result, be it a statistical inference in a scientific paper or a machine learning algorithm in production. This long way is often bumpy, highly iterative and time consuming. However, EDA might be the most important part of data analysis, because it helps to generate hypothesis, which then determine THE final RESULT. Thus, in this post I'll provide the simplest and most effective ways to explore data in R, which will significantly speed up your work. Moreover, we'll go one step beyond EDA by starting to test our hypotheses with simple statistical tests.</description>
      <category>EDA</category>
      <category>videos</category>
      <category>data wrangling</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress/DEDA_thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>How to impute missing values with Machine Learning in R</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r</link>
      <description>Imputation simply means - replacing a missing value with a value that makes sense. But how can we get such values? Well, we'll use Machine Learning algorithms, because they have a high prediction power. So, in this post we'll learn how to impute missing values easily and effectively.</description>
      <category>videos</category>
      <category>data wrangling</category>
      <category>visualization</category>
      <category>machine learning</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r/thumbnail_missing_values.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Null Hypothesis, Alternative Hypothesis and Hypothesis Testing</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good</link>
      <description>Hypothesis testing is one of the most important concepts in (frequentiest) statistics and science. However, most people who test hypotheses are scientists, but not statisticians. That's why scientists often do not test hypotheses properly, without any bad intension—Å. So, in this blog-post we'll break down hypothesis testing in small parts and try to properly understand every of them.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>What is p-value and why we need it</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation</link>
      <description>Why do we need p-values? Well, they help to **make decisions** and **answer the question whether we found something new or not**. But despite the fact that **p-values are** actually **useful**, they are **far from perfect**! And while everyone uses p-values, understanding them (and using them correctly) is very hard. The definition of the p-value from the book is often correct but rarely intuitive. Intuitive explanations are often not entirely correct. So, in this blog-post (and video) we‚Äôll start with an intuitive (and not entirely correct) definition and will gradually build up the understanding of the p-value step by step. Thus, I don‚Äôt recommend to skip any part of this blog (or video). We‚Äôll also talk about how to use and interpret p-values correctly in order to **make better decisions and better science**.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R package reviews {DataExplorer} explore your data!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data</link>
      <description>What is the best way to explore the data quick? I think it's visualization. And what it the best way to visualize the data quick? I think it's - {DataExplorer} package, because it can visualize all your data in seconds using only one function! Check this out...</description>
      <category>R package reviews</category>
      <category>EDA</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data</guid>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data/2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Survival analysis 2: parametric survival models</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models</link>
      <description>The non-parametric Kaplan-Meier method (KM) can not describe survival probability by a smooth function, which means it can not predict anything. The parametric models (e.g. Exponential, Weibull etc.) can! Besides, in case where parametric models are appropriate, they are more exact, more effective and more informative than KM or Cox. However, unfortunately, this step is often left out due to the rear use of parametric models. In this post we‚Äôll try to close this gap.</description>
      <category>survival analysis</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models</guid>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models/thumbnail_survival_2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {performance} check how good your model is! </title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is</link>
      <description>There are several indicators of model quality, e.g. $R^2$ or AIC, and several assumption for every model which supposed to be checked, e.g. normality of residuals, multicollinearity etc.. R provides solutions for every indicator or assumption you can imagine. However, they are usually spread around different packages and functions. {performance} package brings all of quality indicators and all of the assumption under one roof. Thus, for me it became the one-stop solution for modelling.</description>
      <category>R package reviews</category>
      <category>videos</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is</guid>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is/14.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Survival analysis 1: a gentle introduction into Kaplan-Meier Curves</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves</link>
      <description>Survival time analysis is necessary in any study which investigates the time to a particular outcome of interest. Cancer studies in the medicine and the first failure of the car in the engineering field (failure time analysis) are good examples. The outcome of interest could be death, remission to relapse, progression, or failure. Point in time of reaching that outcome is generally called the event. Thank goodness, not every ‚Äúevent‚Äù is fatal üòÉ, but can sometimes even be a favorable outcome such as discharge from hospital. And thus, survival analysis is also a generic term, because it is not only about survival.</description>
      <category>survival analysis</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves</guid>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves/thumbnail_survival_1.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {janitor} clean your data!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data</link>
      <description>Data Scientists spend up to 80% of their time cleaning and preparing data for analysis. " Happy families are all alike; every unhappy family is unhappy in its own way" ‚Äî Leo Tolstoy. "Like families, tidy datasets are all alike but every messy dataset is messy in its own way" - Hadley Wickham. Thats when "janitor" helps to clean the mess.</description>
      <category>R package reviews</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data</guid>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data/11.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>How to visualize models, their assumptions and post-hocs</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs</link>
      <description>A picture is worth a thousand words! This article shows how to visualize results of 16 different models in R: from a simple linear model to a multiple-additive-non-linear-mixed-effects model. Among them are logistic, multinomial, additive and survival models with and without interactions. **Goal: minimum R code &amp; maximum output!** We'll also go a bit beyond only model visualization. So, don't miss the bonuses üòâ.</description>
      <category>visualization</category>
      <category>videos</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs</guid>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs/thumbnail_visualize_models.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>How to create a blog or a website in R with {Distill} package</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package</link>
      <description>If you're not online, you don't exist. A personal webpage or a blog became the business card of the digital century. It shows who you are and what you are capable of. Thus: show, don't tell.</description>
      <category>R &amp; the Web</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package</guid>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package/images/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
  </channel>
</rss>
